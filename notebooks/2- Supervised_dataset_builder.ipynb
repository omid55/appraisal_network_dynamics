{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# Generating a supervised dataset from the Jeopardy-like logs\n",
    "# ===========================================================\n",
    "\n",
    "## Goals:\n",
    "####   1. Generate different networks from log (sentiment, emotion, and reply duration based)\n",
    "####   2. Generate text embedding data\n",
    "####   3. Map all to influence (appraisal) matrix as the groundtruth to estimate\n",
    "####   4. Use LSTM to take the order (time) also into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last update: 04 Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/omid/.local/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imp\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "%matplotlib inline\n",
    "\n",
    "# import Softmax_Loss\n",
    "import text_processor\n",
    "import pogs_jeopardy_log_lib\n",
    "import broadcast_network_extraction\n",
    "import utils\n",
    "from mytools import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload():\n",
    "    imp.reload(pogs_jeopardy_log_lib)\n",
    "    imp.reload(text_processor)\n",
    "    imp.reload(utils)\n",
    "    imp.reload(broadcast_network_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_extractor = broadcast_network_extraction.NetworkExtraction()\n",
    "content_fixer = text_processor.FormalEnglishTranslator('../bagofwords/slang.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/omid/Datasets/Jeopardy/'\n",
    "time_window = [2, 10]\n",
    "apply_content_fixer = True\n",
    "fix_spelling = False\n",
    "start_index = 0\n",
    "skip_matrices_not_completely_from_members = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.load_it(directory+'Teams_logs.pk')\n",
    "contents = utils.load_it(directory+'Teams_contents.pk')\n",
    "networks = utils.load_it(directory+'Teams_networks.pk')\n",
    "supervised_data = utils.load_it(directory+'supervised_data.pk')\n",
    "contents_embeddings = utils.load_it(directory + 'content_embeddings_with_bert_base.pk')\n",
    "individual_performance_rates = utils.load_it(directory + 'Teams_individual_performance.pk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading teams' logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/pogs_jeopardy_log_lib.py:390: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  event_log_no_message[\"sender_subject_id\"] = pd.to_numeric(event_log_no_message[\"sender_subject_id\"])\n",
      "../src/pogs_jeopardy_log_lib.py:600: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  elNoMessage[\"sender_subject_id\"] = pd.to_numeric(elNoMessage[\"sender_subject_id\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 10 ...\n",
      "Processing team 11 ...\n",
      "Processing team 12 ...\n",
      "Processing team 13 ...\n",
      "Processing team 14 ...\n",
      "Processing team 15 ...\n",
      "Processing team 16 ...\n",
      "Processing team 17 ...\n",
      "Processing team 19 ...\n",
      "Processing team 20 ...\n",
      "Processing team 21 ...\n",
      "Processing team 22 ...\n",
      "Processing team 23 ...\n",
      "Processing team 27 ...\n",
      "Processing team 28 ...\n",
      "Processing team 30 ...\n",
      "Processing team 31 ...\n",
      "Processing team 32 ...\n",
      "Processing team 33 ...\n",
      "Processing team 34 ...\n",
      "Processing team 35 ...\n",
      "Processing team 36 ...\n",
      "Processing team 37 ...\n",
      "Processing team 38 ...\n",
      "Processing team 39 ...\n",
      "Processing team 40 ...\n",
      "Processing team 41 ...\n",
      "Processing team 42 ...\n",
      "Processing team 43 ...\n",
      "Processing team 44 ...\n",
      "Processing team 45 ...\n",
      "Processing team 46 ...\n",
      "Processing team 47 ...\n",
      "Processing team 48 ...\n",
      "Processing team 49 ...\n",
      "Processing team 50 ...\n",
      "Team 50 is not found in the logs. There is nothing we can do.\n",
      "Processing team 54 ...\n",
      "Team 54 is not found in the logs. There is nothing we can do.\n",
      "Processing team 61 ...\n",
      "Team 61 is not found in the logs. There is nothing we can do.\n",
      "Processing team 62 ...\n",
      "Team 62 is not found in the logs. There is nothing we can do.\n",
      "Processing team 63 ...\n",
      "Team 63 is not found in the logs. There is nothing we can do.\n",
      "Processing team 69 ...\n",
      "Team 69 is not found in the logs. There is nothing we can do.\n",
      "Processing team 70 ...\n",
      "Processing team 71 ...\n",
      "Processing team 72 ...\n",
      "Processing team 73 ...\n",
      "Processing team 74 ...\n",
      "Processing team 75 ...\n",
      "Processing team 77 ...\n",
      "Processing team 79 ...\n",
      "Processing team 80 ...\n",
      "Team 80 is not found in the logs. There is nothing we can do.\n",
      "Processing team 82 ...\n",
      "Processing team 84 ...\n",
      "Processing team 85 ...\n",
      "Processing team 86 ...\n",
      "Team 86 is not found in the logs. There is nothing we can do.\n",
      "Processing team 87 ...\n",
      "Processing team 88 ...\n",
      "It took 12.50 minutes.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    teams = pd.read_csv(\n",
    "        directory+\"team.csv\",\n",
    "        sep=',',\n",
    "        quotechar=\"|\",\n",
    "        names=[\"id\",\"sessionId\",\"roundId\", \"taskId\"])\n",
    "    data = {}\n",
    "    for team_id in teams.id:\n",
    "        print(\"Processing team\", team_id, '...')\n",
    "        try:\n",
    "            data[team_id] = pogs_jeopardy_log_lib.TeamLogProcessor(\n",
    "                team_id=team_id, logs_directory_path=directory)\n",
    "        except pogs_jeopardy_log_lib.EventLogsNotLoadedError as e:\n",
    "            print('Team {} is not found in the logs. There is nothing we can do.'.format(team_id))\n",
    "            continue\n",
    "        except Exception as e2:\n",
    "            print('Team {} had some problems. Check.'.format(team_id))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omid/Datasets/Jeopardy/Teams_logs.pk is successfully saved.\n"
     ]
    }
   ],
   "source": [
    "utils.save_it(data, directory+'Teams_logs.pk', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 70, 71, 72, 73, 74, 75, 77, 79, 82, 84, 85, 87, 88])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 :  8 9\n",
      "16 :  3 2\n",
      "27 :  2 1\n",
      "35 :  1 0\n",
      "40 :  7 6\n",
      "70 :  7 8\n"
     ]
    }
   ],
   "source": [
    "# for team_id, team_log in data.items():\n",
    "#     messagesby5 = len(team_log.messages) // 5\n",
    "#     matrices = len(team_log.member_influences)\n",
    "#     if messagesby5 != matrices:\n",
    "#         print(team_id, ': ', messagesby5, matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the language of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 1.20 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    if apply_content_fixer:\n",
    "        for team_id, team_log in data.items():\n",
    "            for i in range(len(team_log.messages)):\n",
    "                team_log.messages[i] = content_fixer.translate_messages(\n",
    "                    messages=team_log.messages[i],\n",
    "                    message_column_name='event_content',\n",
    "                    fix_spelling=fix_spelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comibing logs before reporting the appraisal matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 7 ...\n",
      "Processing team 10 ...\n",
      "Processing team 11 ...\n",
      "Processing team 12 ...\n",
      "Processing team 13 ...\n",
      "Processing team 14 ...\n",
      "Processing team 15 ...\n",
      "Processing team 16 ...\n",
      "Processing team 17 ...\n",
      "Processing team 19 ...\n",
      "Processing team 20 ...\n",
      "Processing team 21 ...\n",
      "Processing team 22 ...\n",
      "Processing team 23 ...\n",
      "Processing team 27 ...\n",
      "Processing team 28 ...\n",
      "Processing team 30 ...\n",
      "Processing team 31 ...\n",
      "Processing team 32 ...\n",
      "Processing team 33 ...\n",
      "Processing team 34 ...\n",
      "Processing team 35 ...\n",
      "Team 35 does not have enough logs.\n",
      "Processing team 36 ...\n",
      "Processing team 37 ...\n",
      "Processing team 38 ...\n",
      "Processing team 39 ...\n",
      "Processing team 40 ...\n",
      "Processing team 41 ...\n",
      "Processing team 42 ...\n",
      "Processing team 43 ...\n",
      "Processing team 44 ...\n",
      "Processing team 45 ...\n",
      "Processing team 46 ...\n",
      "Processing team 47 ...\n",
      "Processing team 48 ...\n",
      "Processing team 49 ...\n",
      "Processing team 70 ...\n",
      "Processing team 71 ...\n",
      "Processing team 72 ...\n",
      "Team 72 does not have enough logs.\n",
      "Processing team 73 ...\n",
      "Team 73 does not have enough logs.\n",
      "Processing team 74 ...\n",
      "Processing team 75 ...\n",
      "Processing team 77 ...\n",
      "Processing team 79 ...\n",
      "Processing team 82 ...\n",
      "Processing team 84 ...\n",
      "Processing team 85 ...\n",
      "Processing team 87 ...\n",
      "Processing team 88 ...\n"
     ]
    }
   ],
   "source": [
    "combined_logs = {}\n",
    "for team_id, team_log in data.items():\n",
    "    print(\"Processing team\", team_id, '...')\n",
    "    this_team_nets = []\n",
    "    this_team_number_of_networks = min(\n",
    "        len(team_log.messages) // 5,\n",
    "        len(team_log.member_influences))\n",
    "    all_messages_before_appraisal_reports = []\n",
    "    for i in range(this_team_number_of_networks):\n",
    "        all_messages_before_appraisal_reports.append(\n",
    "            pd.concat(\n",
    "                [team_log.messages[i] for i in np.arange(i * 5, i * 5 + 5)]))\n",
    "    if len(all_messages_before_appraisal_reports) > 0:\n",
    "        combined_logs[team_id] = all_messages_before_appraisal_reports\n",
    "    else:\n",
    "        print('Team', team_id, 'does not have enough logs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting differnet networks from the combined logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 7 ...\n",
      "Processing team 10 ...\n",
      "Processing team 11 ...\n",
      "Processing team 12 ...\n",
      "Processing team 13 ...\n",
      "Processing team 14 ...\n",
      "Processing team 15 ...\n",
      "Processing team 16 ...\n",
      "Processing team 17 ...\n",
      "Processing team 19 ...\n",
      "Processing team 20 ...\n",
      "Processing team 21 ...\n",
      "Processing team 22 ...\n",
      "Processing team 23 ...\n",
      "Processing team 27 ...\n",
      "Processing team 28 ...\n",
      "Processing team 30 ...\n",
      "Processing team 31 ...\n",
      "Processing team 32 ...\n",
      "Processing team 33 ...\n",
      "Processing team 34 ...\n",
      "Processing team 36 ...\n",
      "Processing team 37 ...\n",
      "Processing team 38 ...\n",
      "Processing team 39 ...\n",
      "Processing team 40 ...\n",
      "Processing team 41 ...\n",
      "Processing team 42 ...\n",
      "Processing team 43 ...\n",
      "Processing team 44 ...\n",
      "Processing team 45 ...\n",
      "Processing team 46 ...\n",
      "Processing team 47 ...\n",
      "Processing team 48 ...\n",
      "Processing team 49 ...\n",
      "Processing team 70 ...\n",
      "Processing team 71 ...\n",
      "Processing team 74 ...\n",
      "Processing team 75 ...\n",
      "Processing team 77 ...\n",
      "Processing team 79 ...\n",
      "Processing team 82 ...\n",
      "Processing team 84 ...\n",
      "Processing team 85 ...\n",
      "Processing team 87 ...\n",
      "Processing team 88 ...\n",
      "It took 3.97 minutes.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    networks = {}\n",
    "    for team_id, all_messages_before_appraisal_reports in combined_logs.items():\n",
    "        print(\"Processing team\", team_id, '...')\n",
    "        this_team_nets = []\n",
    "        for all_messages_before_appraisal_report in all_messages_before_appraisal_reports:\n",
    "            reply_duration_net = net_extractor.extract_network_from_broadcast(            \n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.REPLY_DURATION,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.SUM,\n",
    "                gamma=0.15,\n",
    "                node_list=data[team_id].members)\n",
    "            sentiment_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.SENTIMENT,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.SUM,\n",
    "                node_list=data[team_id].members)\n",
    "            emotion_arousal_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.EMOTION_AROUSAL,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.SUM,\n",
    "                node_list=data[team_id].members)\n",
    "            emotion_dominance_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.EMOTION_DOMINANCE,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.SUM,\n",
    "                node_list=data[team_id].members)\n",
    "            emotion_valence_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.EMOTION_VALENCE,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.SUM,\n",
    "                node_list=data[team_id].members)\n",
    "            if len(reply_duration_net.nodes()) > 0:\n",
    "                this_team_nets.append({\n",
    "                    'sentiment': sentiment_net,\n",
    "                    'reply_duration': reply_duration_net,\n",
    "                    'emotion_arousal': emotion_arousal_net,\n",
    "                    'emotion_dominance': emotion_dominance_net,\n",
    "                    'emotion_valence': emotion_valence_net})\n",
    "        if len(this_team_nets) > 0:\n",
    "            networks[team_id] = this_team_nets\n",
    "        else:\n",
    "            print('Team', team_id, 'did not have enough networks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omid/Datasets/Jeopardy/Teams_networks.pk is successfully saved.\n"
     ]
    }
   ],
   "source": [
    "utils.save_it(networks, directory+'Teams_networks.pk', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theses teams did not have networks:  {72, 73, 35}\n"
     ]
    }
   ],
   "source": [
    "print('Theses teams did not have networks: ',\n",
    "      set(data.keys()) - set(networks.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Just saving the appraisal matrices and performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_data = {}\n",
    "for team_id, team_log in data.items():\n",
    "    short_data[team_id] = {'scores': team_log.score, 'influences': team_log.member_influences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_it(short_data, directory+'Appraisals_and_scores_data.pk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting content of all texts that every person sent from combined logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 7 ...\n",
      "Processing team 10 ...\n",
      "Processing team 11 ...\n",
      "Processing team 12 ...\n",
      "Processing team 13 ...\n",
      "Processing team 14 ...\n",
      "Processing team 15 ...\n",
      "Processing team 16 ...\n",
      "Processing team 17 ...\n",
      "Processing team 19 ...\n",
      "Processing team 20 ...\n",
      "Processing team 21 ...\n",
      "Processing team 22 ...\n",
      "Processing team 23 ...\n",
      "Processing team 27 ...\n",
      "Processing team 28 ...\n",
      "Processing team 30 ...\n",
      "Processing team 31 ...\n",
      "Processing team 32 ...\n",
      "Processing team 33 ...\n",
      "Processing team 34 ...\n",
      "Processing team 36 ...\n",
      "Processing team 37 ...\n",
      "Processing team 38 ...\n",
      "Processing team 39 ...\n",
      "Processing team 40 ...\n",
      "Processing team 41 ...\n",
      "Processing team 42 ...\n",
      "Processing team 43 ...\n",
      "Processing team 44 ...\n",
      "Processing team 45 ...\n",
      "Processing team 46 ...\n",
      "Processing team 47 ...\n",
      "Processing team 48 ...\n",
      "Processing team 49 ...\n",
      "Processing team 70 ...\n",
      "Processing team 71 ...\n",
      "Processing team 74 ...\n",
      "Processing team 75 ...\n",
      "Processing team 77 ...\n",
      "Processing team 79 ...\n",
      "Processing team 82 ...\n",
      "Processing team 84 ...\n",
      "Processing team 85 ...\n",
      "Processing team 87 ...\n",
      "Processing team 88 ...\n"
     ]
    }
   ],
   "source": [
    "contents = {}\n",
    "for team_id, all_messages_before_appraisal_reports in combined_logs.items():\n",
    "    print(\"Processing team\", team_id, '...')\n",
    "    member_concat_messages = []\n",
    "    for all_messages_before_appraisal_report in all_messages_before_appraisal_reports:\n",
    "        this_time_member_concat_messages = []\n",
    "        for member in sorted(data[team_id].members):\n",
    "            sentences = '[CLS] ' + ' [SEP] '.join(\n",
    "                all_messages_before_appraisal_report[\n",
    "                    all_messages_before_appraisal_report.sender_subject_id == member].event_content) + ' [SEP]'\n",
    "            this_time_member_concat_messages.append(sentences)\n",
    "        member_concat_messages.append(this_time_member_concat_messages)\n",
    "    contents[team_id] = member_concat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omid/Datasets/Jeopardy/Teams_contents.pk is successfully saved.\n"
     ]
    }
   ],
   "source": [
    "utils.save_it(contents, directory+'Teams_contents.pk', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After using colabs to generate embedding vectors from bert model for contents we load the pickled file in the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_embeddings = utils.load_it(directory + 'content_embeddings_with_bert_large_clssep_added.pk')\n",
    "# contents_embeddings = utils.load_it(directory + 'content_embeddings_with_bert_base_clssep_added.pk')\n",
    "# contents_embeddings = utils.load_it(directory + 'content_embeddings_with_bert_base.pk')\n",
    "# contents_embeddings = utils.load_it(directory + 'content_embeddings_with_roberta_base.pk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting individual performance (skills) to add to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_performance_rates = defaultdict(list)\n",
    "\n",
    "hardness_weights = {\n",
    "    pogs_jeopardy_log_lib.Level.EASY: 1,\n",
    "    pogs_jeopardy_log_lib.Level.MEDIUM: 2,\n",
    "    pogs_jeopardy_log_lib.Level.HARD: 3}\n",
    "questions = data[37].game_info.questions\n",
    "for team_id, team_log in data.items():\n",
    "    this_team_members_performance = defaultdict(\n",
    "        lambda: {'#correct': 0,\n",
    "                 '#questions': 0,\n",
    "                 '#hardness_weighted_correct': 0,\n",
    "                 '#hardness_weighted_questions': 0})\n",
    "    for index, qid in enumerate(team_log.question_order):\n",
    "        question_hardness_weight = hardness_weights[questions[qid].level]\n",
    "        correct_answer = questions[qid].answer\n",
    "        for member, member_answer in team_log.individual_answers_chosen[qid].items():\n",
    "            this_team_members_performance[member]['#questions'] += 1\n",
    "            this_team_members_performance[member]['#hardness_weighted_questions'] += question_hardness_weight\n",
    "            if member_answer == correct_answer:\n",
    "                this_team_members_performance[member]['#correct'] += 1\n",
    "                this_team_members_performance[member]['#hardness_weighted_correct'] += question_hardness_weight\n",
    "        if (index + 1) % 5 == 0:\n",
    "            so_far_individual_performance = {}\n",
    "            for member in team_log.members:\n",
    "                correct_rate = this_team_members_performance[member]['#correct'] / this_team_members_performance[member]['#questions']\n",
    "                hardness_weighted_correct_rate = this_team_members_performance[member]['#hardness_weighted_correct'] / this_team_members_performance[member]['#hardness_weighted_questions']\n",
    "                so_far_individual_performance[member] = {\n",
    "                    'correct_rate_so_far': correct_rate,\n",
    "                    'hardness_weighted_correct_rate_so_far': hardness_weighted_correct_rate}\n",
    "            individual_performance_rates[team_id].append(so_far_individual_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(individual_performance_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omid/Datasets/Jeopardy/Teams_individual_performance.pk is successfully saved.\n"
     ]
    }
   ],
   "source": [
    "utils.save_it(individual_performance_rates, directory+'Teams_individual_performance.pk', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 7 ...\n",
      "E1: Index: 0 was skipped.\n",
      "E1: Index: 1 was skipped.\n",
      "E1: Index: 2 was skipped.\n",
      "E1: Index: 3 was skipped.\n",
      "E2: Index: 5 was skipped.\n",
      "E2: Index: 6 was skipped.\n",
      "E2: Index: 7 was skipped.\n",
      "Processing team 10 ...\n",
      "Processing team 11 ...\n",
      "E2: Index: 1 was skipped.\n",
      "Processing team 12 ...\n",
      "Processing team 13 ...\n",
      "Processing team 14 ...\n",
      "E2: Index: 2 was skipped.\n",
      "Processing team 15 ...\n",
      "E1: Index: 0 was skipped.\n",
      "E2: Index: 2 was skipped.\n",
      "Processing team 16 ...\n",
      "Processing team 17 ...\n",
      "Processing team 19 ...\n",
      "Processing team 20 ...\n",
      "Processing team 21 ...\n",
      "E2: Index: 3 was skipped.\n",
      "E2: Index: 4 was skipped.\n",
      "E2: Index: 6 was skipped.\n",
      "Processing team 22 ...\n",
      "E2: Index: 3 was skipped.\n",
      "Processing team 23 ...\n",
      "Processing team 27 ...\n",
      "Processing team 28 ...\n",
      "Processing team 30 ...\n",
      "E2: Index: 4 was skipped.\n",
      "Processing team 31 ...\n",
      "Processing team 32 ...\n",
      "Processing team 33 ...\n",
      "E2: Index: 1 was skipped.\n",
      "E2: Index: 8 was skipped.\n",
      "Processing team 34 ...\n",
      "E2: Index: 1 was skipped.\n",
      "Processing team 36 ...\n",
      "Processing team 37 ...\n",
      "Processing team 38 ...\n",
      "Processing team 39 ...\n",
      "Processing team 40 ...\n",
      "Processing team 41 ...\n",
      "E2: Index: 4 was skipped.\n",
      "Processing team 42 ...\n",
      "Processing team 43 ...\n",
      "Processing team 44 ...\n",
      "Processing team 45 ...\n",
      "Processing team 46 ...\n",
      "E1: Index: 0 was skipped.\n",
      "E1: Index: 1 was skipped.\n",
      "Processing team 47 ...\n",
      "E2: Index: 7 was skipped.\n",
      "E2: Index: 8 was skipped.\n",
      "Processing team 48 ...\n",
      "Processing team 49 ...\n",
      "Processing team 70 ...\n",
      "E2: Index: 6 was skipped.\n",
      "Processing team 71 ...\n",
      "E2: Index: 3 was skipped.\n",
      "Processing team 74 ...\n",
      "Processing team 75 ...\n",
      "Processing team 77 ...\n",
      "Processing team 79 ...\n",
      "E2: Index: 1 was skipped.\n",
      "Processing team 82 ...\n",
      "Processing team 84 ...\n",
      "Processing team 85 ...\n",
      "Processing team 87 ...\n",
      "E2: Index: 5 was skipped.\n",
      "Processing team 88 ...\n",
      "It took 0.50 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    X = []\n",
    "    y = []\n",
    "    for team_id, team_log in data.items():\n",
    "        if team_id in networks:\n",
    "            print(\"Processing team\", team_id, '...')\n",
    "\n",
    "            # First influence matrix:\n",
    "            first_index = 0\n",
    "            while first_index < len(networks[team_id]):\n",
    "                influence_matrix = np.matrix(team_log.member_influences[first_index])\n",
    "                if skip_matrices_not_completely_from_members and np.sum(team_log.member_influences_from_data[first_index]) != 16:\n",
    "                    print('E1: Index: {} was skipped.'.format(first_index))\n",
    "                    first_index += 1\n",
    "                    continue\n",
    "                normalized_influence_matrix = utils.shuffle_matrix_in_given_order(\n",
    "                        matrix=influence_matrix,\n",
    "                        order=np.argsort(team_log.members)) / 100\n",
    "                first_row_stochastic_normalized_influence_matrix = np.matrix(\n",
    "                    utils.make_matrix_row_stochastic(normalized_influence_matrix))\n",
    "                previous_row_stochastic_normalized_influence_matrix = first_row_stochastic_normalized_influence_matrix.copy()\n",
    "                break\n",
    "\n",
    "            # Average of previous influence matrices:\n",
    "            previous_influence_matrices_cnt = 1\n",
    "            average_of_previous_influence_matrices = first_row_stochastic_normalized_influence_matrix.copy()\n",
    "            for index in range(first_index + 1, len(networks[team_id])):\n",
    "                influence_matrix = np.matrix(team_log.member_influences[index])\n",
    "                if skip_matrices_not_completely_from_members and np.sum(team_log.member_influences_from_data[index]) != 16:\n",
    "                    print('E2: Index: {} was skipped.'.format(index))\n",
    "                    continue\n",
    "\n",
    "                # Individual performance:\n",
    "                individual_performance = np.zeros(4)\n",
    "                individual_performance_hardness_weighted = np.zeros(4)\n",
    "                perf_rates = individual_performance_rates[team_id][index]\n",
    "                for i, member in enumerate(sorted(team_log.members)):\n",
    "                    individual_performance[i] = perf_rates[member]['correct_rate_so_far']\n",
    "                    individual_performance_hardness_weighted[i] = perf_rates[member]['hardness_weighted_correct_rate_so_far']\n",
    "\n",
    "                # Networks:\n",
    "                network = networks[team_id][index]\n",
    "\n",
    "                # Contents:\n",
    "                contents_embedding = contents_embeddings[team_id][index]\n",
    "\n",
    "                # Average of previous influence matrices:\n",
    "                normalized_influence_matrix = utils.shuffle_matrix_in_given_order(\n",
    "                    matrix=influence_matrix,\n",
    "                    order=np.argsort(team_log.members)) / 100\n",
    "                row_stochastic_normalized_influence_matrix = np.matrix(\n",
    "                    utils.make_matrix_row_stochastic(normalized_influence_matrix))\n",
    "\n",
    "                # Multi-class classification (who is (are) the most influential individual(s)):\n",
    "                most_influentials = utils.most_influential_on_others(\n",
    "                    influence_matrix=row_stochastic_normalized_influence_matrix,\n",
    "                    remove_self_influence=True)\n",
    "\n",
    "                # Combining all features together:\n",
    "                y.append({\n",
    "                    'influence_matrix': row_stochastic_normalized_influence_matrix,\n",
    "                    'most_influentials': most_influentials})\n",
    "                X.append({\n",
    "                    'individual_performance': individual_performance,\n",
    "                    'individual_performance_hardness_weighted': individual_performance_hardness_weighted,\n",
    "                    'content_embedding_matrix': contents_embedding,\n",
    "                    'first_influence_matrix': first_row_stochastic_normalized_influence_matrix,\n",
    "                    'previous_influence_matrix': previous_row_stochastic_normalized_influence_matrix,\n",
    "                    'average_of_previous_influence_matrices': average_of_previous_influence_matrices / previous_influence_matrices_cnt,\n",
    "                    'reply_duration': nx.adj_matrix(network['reply_duration']).todense(),\n",
    "                    'sentiment': nx.adj_matrix(network['sentiment']).todense(),\n",
    "                    'emotion_arousal': nx.adj_matrix(network['emotion_arousal']).todense(),\n",
    "                    'emotion_dominance': nx.adj_matrix(network['emotion_dominance']).todense(),\n",
    "                    'emotion_valence': nx.adj_matrix(network['emotion_valence']).todense()})\n",
    "                previous_row_stochastic_normalized_influence_matrix = row_stochastic_normalized_influence_matrix.copy()\n",
    "                average_of_previous_influence_matrices += row_stochastic_normalized_influence_matrix\n",
    "                previous_influence_matrices_cnt += 1\n",
    "\n",
    "    supervised_data = {'X': X, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(supervised_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['individual_performance_hardness_weighted', 'previous_influence_matrix', 'reply_duration', 'emotion_valence', 'average_of_previous_influence_matrices', 'sentiment', 'individual_performance', 'content_embedding_matrix', 'emotion_arousal', 'first_influence_matrix', 'emotion_dominance'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(supervised_data['X'][0].keys()))\n",
    "supervised_data['X'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omid/Datasets/Jeopardy/supervised_data_Jan28.pk is successfully saved.\n"
     ]
    }
   ],
   "source": [
    "utils.save_it(supervised_data, directory+'supervised_data_Jan28.pk', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(directory+'supervised_data_Jan28_pickle2.pk', 'wb') as handle:\n",
    "    pk.dump(supervised_data, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
