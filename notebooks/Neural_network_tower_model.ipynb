{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# Solve the estimation problem with neural network tower model on the supervised dataset from the Jeopardy-like logs\n",
    "# ===========================================================\n",
    "\n",
    "Goals:\n",
    "1. Split the data into test and train\n",
    "2. Formulate the neural network based model\n",
    "3. Compute train and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last update: 05 Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv1D, LSTM, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "from mytimer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = '/home/omid/Datasets/Jeopardy/supervised_data.pk'\n",
    "test_fraction = 0.2\n",
    "runs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix_err(true_matrix: np.matrix, pred_matrix: np.matrix, type_str: str = 'frob_norm') -> float:\n",
    "    if type_str == 'frob_norm':\n",
    "        frob_norm_of_difference = np.linalg.norm(true_matrix - pred_matrix)\n",
    "        err = frob_norm_of_difference / np.linalg.norm(true_matrix)\n",
    "        return err\n",
    "    elif type_str == 'corr':\n",
    "#         (r, p) = sp.stats.spearmanr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        (r, p) = sp.stats.pearsonr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        if p > 0.05:\n",
    "            r = 0\n",
    "        return r\n",
    "    else:\n",
    "        raise ValueError('Wrong type_str was given.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eigvec_of_laplacian(A: np.matrix) -> np.matrix:\n",
    "#     D = np.diag(np.array(np.sum(A, axis=0))[0])\n",
    "#     L = D - A\n",
    "#     return np.matrix(np.linalg.eig(L)[1])\n",
    "    n, m = A.shape\n",
    "    diags = A.sum(axis=1).flatten()\n",
    "    D = sp.sparse.spdiags(diags, [0], m, n, format='csr')\n",
    "    L = D - A\n",
    "    with sp.errstate(divide='ignore'):\n",
    "        diags_sqrt = 1.0/sp.sqrt(diags)\n",
    "    diags_sqrt[sp.isinf(diags_sqrt)] = 0\n",
    "    DH = sp.sparse.spdiags(diags_sqrt, [0], m, n, format='csr')\n",
    "    DH = DH.todense()\n",
    "    normalized_L = DH.dot(L.dot(DH))\n",
    "    return normalized_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape, dtype=None):\n",
    "    return np.ones(shape) * 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_it(data_fpath)\n",
    "print(len(data['X']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = []\n",
    "for i in range(len(data['y'])):\n",
    "    mats.append(data['y'][i]['influence_matrix'] / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26338279, 0.24830861, 0.25548961, 0.23243323],\n",
       "       [0.2189911 , 0.33845697, 0.2158457 , 0.2227003 ],\n",
       "       [0.21379822, 0.2511276 , 0.30367953, 0.22474777],\n",
       "       [0.25338279, 0.24091988, 0.24379822, 0.26367953]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12754406, 0.08032826, 0.09008641, 0.07827526],\n",
       "       [0.10004831, 0.19647938, 0.08964129, 0.11201212],\n",
       "       [0.09734972, 0.12308318, 0.17451618, 0.10372017],\n",
       "       [0.0940633 , 0.06791981, 0.06305615, 0.09161002]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mats, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulating the tower model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only content embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7396 - accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7387 - accuracy: 0.0188\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 0.7385 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7382 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7379 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7377 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7372 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7373 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7364 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7367 - accuracy: 0.0188\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7388 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7379 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7375 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7372 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7366 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7361 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7363 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7359 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7353 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7355 - accuracy: 0.0163\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7384 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7376 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7376 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7368 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7369 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7366 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7369 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7360 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7364 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7363 - accuracy: 0.0181\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7395 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 124us/sample - loss: 0.7383 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 103us/sample - loss: 0.7384 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7384 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7380 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7379 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7375 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7371 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7371 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7362 - accuracy: 0.0177\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7395 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 0.7391 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.7385 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7387 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7383 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7376 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7373 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7373 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7370 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7373 - accuracy: 0.0165\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7386 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.7383 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7377 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7370 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7373 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7363 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7366 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7361 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7360 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7354 - accuracy: 0.0181\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7392 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7384 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7384 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7378 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7375 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7371 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7364 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7365 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7357 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7356 - accuracy: 0.0191\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7405 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.7396 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 103us/sample - loss: 0.7392 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7386 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7381 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7387 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7378 - accuracy: 0.0179\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7372 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7368 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7370 - accuracy: 0.0179\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7389 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7381 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7379 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7373 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7372 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7369 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7365 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7362 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7360 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7354 - accuracy: 0.0167\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7391 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 109us/sample - loss: 0.7384 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7381 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7372 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7376 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7370 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7371 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7370 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7367 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7363 - accuracy: 0.0191\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7385 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 120us/sample - loss: 0.7380 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7376 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7375 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7373 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7364 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7369 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7361 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7366 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7358 - accuracy: 0.0179\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7383 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7372 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7372 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7372 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7366 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7361 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7360 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7358 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7355 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7353 - accuracy: 0.0195\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7399 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7389 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7386 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7381 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7381 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7376 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7368 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7371 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7369 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7370 - accuracy: 0.0156\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7393 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7387 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7373 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7372 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7374 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7369 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7364 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7366 - accuracy: 0.0186\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7391 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7384 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7382 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7377 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7378 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7371 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7366 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7364 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7362 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7357 - accuracy: 0.0163\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7381 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.7379 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 0.7376 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7369 - accuracy: 0.0193\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7365 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7362 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7358 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7358 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7356 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7361 - accuracy: 0.0193\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7391 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7385 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7384 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7377 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7383 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7377 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7368 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7368 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7365 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7364 - accuracy: 0.0167\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7389 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7381 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7377 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7377 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7374 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7372 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7373 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 0.7366 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7360 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7358 - accuracy: 0.0177\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7385 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7383 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7383 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7379 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7378 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7371 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7371 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7368 - accuracy: 0.0170\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7389 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7380 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7379 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7374 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7374 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7373 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7368 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7366 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7363 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7357 - accuracy: 0.0191\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7387 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7382 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7376 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7376 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7373 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7368 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7366 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7367 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7366 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7362 - accuracy: 0.0193\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7387 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7379 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7378 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7378 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7374 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7374 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7371 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7368 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7365 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7367 - accuracy: 0.0165\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7393 - accuracy: 0.0151\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7386 - accuracy: 0.0151\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7381 - accuracy: 0.0151\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7381 - accuracy: 0.0151\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7373 - accuracy: 0.0151\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7371 - accuracy: 0.0151\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7374 - accuracy: 0.0151\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7368 - accuracy: 0.0151\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7362 - accuracy: 0.0151\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7364 - accuracy: 0.0151\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7383 - accuracy: 0.0156\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7378 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.7376 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7377 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7370 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7371 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7368 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7364 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7363 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7361 - accuracy: 0.0156\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7394 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7384 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7382 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7382 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7376 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7377 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7382 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7369 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7371 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7363 - accuracy: 0.0156\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7396 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7396 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7393 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7389 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7380 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7381 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7375 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7375 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7368 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7372 - accuracy: 0.0186\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7401 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7393 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7388 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7387 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7387 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7382 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7386 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7381 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7373 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7371 - accuracy: 0.0177\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7380 - accuracy: 0.0160\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7375 - accuracy: 0.0160\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7374 - accuracy: 0.0160\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7372 - accuracy: 0.0160\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7365 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7361 - accuracy: 0.0160\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7360 - accuracy: 0.0160\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7358 - accuracy: 0.0160\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7356 - accuracy: 0.0160\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7355 - accuracy: 0.0160\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7390 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7385 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7381 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7381 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7377 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7375 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7372 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7371 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7367 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7367 - accuracy: 0.0172\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7400 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7395 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7390 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7386 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7386 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7385 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7382 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7382 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7379 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7377 - accuracy: 0.0163\n",
      "It took 30.30 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']            \n",
    "#             flatten_X_train.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_train.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "#             flatten_X_test.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_test.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu', input_shape=(3072,)),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "#             Dense(16, kernel_initializer='he_normal', activation='softmax')])\n",
    "            Dense(16, kernel_initializer=my_init, activation='softmax')])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "#         model = Sequential([\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 input_shape=(3072,),\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=64,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=16,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='softmax',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1))\n",
    "#         ])\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6358637687891749 +- 0.017407726721425588\n",
      "uniform: 0.3522141490130312 +- 0.018461737356623154\n",
      "model: 0.34663943089383537 +- 0.016315834977931095\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc43614d0f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = True\n",
    "one_type_network = 'reply_duration'   # 'emotion_dominance'\n",
    "input_dim = 80\n",
    "lambda1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1129.2028 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 1064.8313 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1003.3088 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 944.0386 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 888.0018 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 834.2492 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 782.8130 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 733.7862 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 686.8196 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 642.0795 - accuracy: 0.0181\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1139.9742 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1075.5409 - accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1014.2850 - accuracy: 0.0158\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 954.9360 - accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 898.0919 - accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 843.4122 - accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 791.3481 - accuracy: 0.0158\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 741.4664 - accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 693.7342 - accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 648.2541 - accuracy: 0.0158\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1155.9748 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1090.9233 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1029.0111 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 968.2999 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 910.9342 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 856.2688 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 803.3710 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 752.9869 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 704.5878 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 658.8891 - accuracy: 0.0167\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1166.2186 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1100.8335 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1039.0170 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 979.6093 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 922.9814 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 869.0565 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 816.9134 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 767.2183 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 719.6365 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 674.2045 - accuracy: 0.0193\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1144.1854 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 1079.3233 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1017.7338 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 958.4422 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 901.5538 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 847.4018 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 795.4554 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 745.5239 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 698.0062 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 652.8114 - accuracy: 0.0156\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1156.1080 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1090.5628 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 1028.1691 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 968.5407 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 911.9006 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 857.6487 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 805.6659 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 756.2174 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 708.9602 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 663.9904 - accuracy: 0.0167\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1143.5085 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1078.5653 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1016.2720 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 957.1737 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 900.0817 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 845.5307 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 793.4327 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 743.6954 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 696.2274 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 651.1582 - accuracy: 0.0167\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1159.9867 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1096.0405 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1033.7801 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 974.1174 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 916.7466 - accuracy: 0.0177\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 75us/sample - loss: 862.4249 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 810.4289 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 760.2302 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 712.5842 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 667.2200 - accuracy: 0.0177\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1177.5967 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 1112.2172 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1049.9725 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 989.7653 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 931.7611 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 876.5170 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 823.5754 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 772.8690 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 724.5442 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 678.4924 - accuracy: 0.0165\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1173.5135 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1108.9259 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1046.7414 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 987.3347 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 929.5036 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 874.5877 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 821.9335 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 771.0937 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 722.9175 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 676.6407 - accuracy: 0.0179\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1148.4148 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1083.7283 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 1021.9998 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 963.2463 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 907.0173 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 852.7526 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 801.2573 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 751.7239 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 704.4360 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 659.2564 - accuracy: 0.0177\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1166.1102 - accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1100.7097 - accuracy: 0.0188\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1037.8269 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 977.7264 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 920.4520 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 865.4415 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 813.2466 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 763.0242 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 715.1081 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 669.3643 - accuracy: 0.0188\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1140.4614 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1074.4964 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1013.3498 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 953.7008 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 896.8580 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 842.7106 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 790.7675 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 741.4915 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 694.4414 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 649.8993 - accuracy: 0.0177\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1171.5424 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1107.0800 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1045.5637 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 986.0753 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 928.6300 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 873.6497 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 821.0766 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 770.7407 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 722.5543 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 676.6280 - accuracy: 0.0193\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1146.3331 - accuracy: 0.0153\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1081.2212 - accuracy: 0.0153\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1019.7446 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 960.3851 - accuracy: 0.0153\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 903.4525 - accuracy: 0.0153\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 848.9426 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 796.4592 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 746.7560 - accuracy: 0.0153\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 699.3042 - accuracy: 0.0153\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 654.3406 - accuracy: 0.0153\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 3ms/sample - loss: 1135.1535 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 1071.0275 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 1008.8973 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 949.9622 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 892.7380 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 838.4916 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 786.4447 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 736.9422 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 689.7770 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 644.7653 - accuracy: 0.0181\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1161.7091 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1095.6503 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1033.5331 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 973.4751 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 916.1235 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 861.1882 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 809.0379 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 759.1021 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 711.4668 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 665.8519 - accuracy: 0.0167\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.4299 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1083.3459 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1021.4114 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 962.3643 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 905.9802 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 852.0611 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 800.2745 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 751.0585 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 704.2451 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 659.3552 - accuracy: 0.0177\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1156.1761 - accuracy: 0.0153\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1091.2596 - accuracy: 0.0153\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1028.8294 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 968.9954 - accuracy: 0.0153\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 911.8857 - accuracy: 0.0153\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 857.2292 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 805.2266 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 755.4080 - accuracy: 0.0153\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 707.9492 - accuracy: 0.0153\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 662.5152 - accuracy: 0.0153\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1148.6885 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1083.5594 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1021.5588 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 962.2911 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 905.5994 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 851.2257 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 799.3261 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 749.3376 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 701.6837 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 656.0672 - accuracy: 0.0195\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1171.1398 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1104.9599 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1041.6840 - accuracy: 0.0197\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 981.1663 - accuracy: 0.0197\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 924.3704 - accuracy: 0.0197\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 869.1978 - accuracy: 0.0197\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 816.4479 - accuracy: 0.0197\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 766.0721 - accuracy: 0.0197\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 717.7793 - accuracy: 0.0197\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 672.2426 - accuracy: 0.0197\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.1805 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1083.1277 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1021.2257 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 961.9440 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 905.2668 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 850.9572 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 798.9083 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 749.1899 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 701.9336 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 656.7258 - accuracy: 0.0179\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1132.1559 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1066.4077 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1004.7243 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 945.1560 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 888.2962 - accuracy: 0.0193\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 61us/sample - loss: 833.9246 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 781.9596 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 732.5152 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 685.9425 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 641.3913 - accuracy: 0.0193\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1159.1377 - accuracy: 0.0160\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1093.9618 - accuracy: 0.0160\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1031.2505 - accuracy: 0.0160\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 971.9063 - accuracy: 0.0160\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 914.4294 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 859.8280 - accuracy: 0.0160\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 807.2810 - accuracy: 0.0160\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 756.9763 - accuracy: 0.0160\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 709.1444 - accuracy: 0.0160\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 663.4555 - accuracy: 0.0160\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1138.2437 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1072.4098 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1010.2879 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 950.3695 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 893.7916 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 839.6181 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 787.5018 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 738.4247 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 691.2649 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 646.4815 - accuracy: 0.0167\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1153.9272 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1088.6069 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1027.2105 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 967.5574 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 910.1670 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 855.7661 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 803.7105 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 753.9431 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 706.4912 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 661.3029 - accuracy: 0.0167\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1154.9127 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1089.9382 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1027.5484 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 967.5648 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 909.7255 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 855.2228 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 802.2617 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 752.1714 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 704.3723 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 658.7658 - accuracy: 0.0186\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1157.7748 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1091.6244 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 1028.9416 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 968.7104 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 911.3704 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 856.3421 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 803.3847 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 753.3710 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 705.7298 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 660.5937 - accuracy: 0.0188\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1148.1463 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1083.3388 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1021.8961 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 961.9822 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 905.4330 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 850.8270 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 798.6586 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 748.8168 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 701.3088 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 655.8904 - accuracy: 0.0177\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.6232 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1082.2249 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 1020.0382 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 960.7634 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 903.7219 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 849.2745 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 797.2047 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 747.3739 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 699.9482 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 654.8754 - accuracy: 0.0163\n",
      "It took 40.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim,),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=64,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6310301214868926 +- 0.01399059267030896\n",
      "uniform: 0.34745737869634064 +- 0.017530337002096035\n",
      "model: 0.34513695020571783 +- 0.016975889090539077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc547f7feb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = False\n",
    "one_type_network = 'reply_duration'   # 'emotion_dominance'\n",
    "input_dim = 16\n",
    "lambda1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/omid/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "269/269 [==============================] - 1s 5ms/sample - loss: 2316.7463 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 2183.4574 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2074.5713 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1979.9266 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1894.4858 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1815.4952 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1741.3955 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1670.9995 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1603.6196 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1538.9773 - accuracy: 0.0184\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2450.9399 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 2292.4517 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 2168.4721 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 2066.5708 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1977.8607 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1898.1154 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1823.4210 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1752.8025 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1685.1384 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1620.7432 - accuracy: 0.0179\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2388.0205 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 2243.4778 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2128.1227 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 2029.5754 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1941.9750 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1861.2338 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1786.0395 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1714.7197 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1646.9767 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1581.9344 - accuracy: 0.0193\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2356.2360 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2220.3267 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2108.4744 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 2011.7390 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 1925.9535 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 1847.0319 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1773.0010 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1702.9753 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1635.7740 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1571.1784 - accuracy: 0.0193\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2396.6715 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 2251.2056 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 2135.9138 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2039.7016 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1954.8239 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1877.0427 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1804.3667 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1735.2998 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1669.0223 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1605.4971 - accuracy: 0.0174\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2299.3032 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2177.2090 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 2073.8609 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1982.6824 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1899.5181 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1821.7955 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1748.2063 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1677.9813 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1610.5383 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1545.2336 - accuracy: 0.0167\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2324.0501 - accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 2191.6380 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2083.0006 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1989.2089 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1904.8294 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1826.9468 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1753.7523 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1684.2394 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1617.6341 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1553.8183 - accuracy: 0.0191\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2520.4810 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 2349.8472 - accuracy: 0.0179\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 70us/sample - loss: 2214.7773 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 2104.7400 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 2009.7255 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1925.4602 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1847.6449 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1774.8255 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1705.8209 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1640.4519 - accuracy: 0.0179\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2438.2959 - accuracy: 0.0151\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 2283.4382 - accuracy: 0.0151\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 2160.7340 - accuracy: 0.0151\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2058.2293 - accuracy: 0.0151\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 1969.8852 - accuracy: 0.0151\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1889.2356 - accuracy: 0.0151\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1814.1718 - accuracy: 0.0151\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1743.4460 - accuracy: 0.0151\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1675.9860 - accuracy: 0.0151\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1611.2421 - accuracy: 0.0151\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2363.5804 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 2229.2374 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2120.4864 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 2026.8631 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1942.4040 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1864.1887 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1790.6089 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1720.2925 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1653.1304 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1588.7999 - accuracy: 0.0177\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2431.8131 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 2284.1098 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 2164.9821 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 2064.0368 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1974.6460 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1892.4672 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1816.2226 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1744.0807 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1675.4689 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1609.5355 - accuracy: 0.0156\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2323.8424 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 2197.3442 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2090.5687 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1997.5349 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1912.9364 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1833.8643 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1759.3569 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1688.2503 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1620.5883 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1555.3995 - accuracy: 0.0177\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2312.5504 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 2175.7793 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 2065.1662 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1970.4899 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1886.3214 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1808.7453 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1735.9351 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1666.7718 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1600.5467 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1536.9825 - accuracy: 0.0167\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2329.6424 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2196.4774 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 2087.3506 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 1992.3061 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 1907.2527 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1828.4540 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1754.2159 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1683.4406 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1615.6550 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1550.4778 - accuracy: 0.0193\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2407.5517 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 2255.0614 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2134.0168 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 2032.2323 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1942.8927 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1861.9991 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1786.6767 - accuracy: 0.0174\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 77us/sample - loss: 1715.8591 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1648.2367 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1583.3526 - accuracy: 0.0174\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2326.9215 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 2192.6564 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 2081.9460 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1986.5235 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 1901.4864 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1823.1826 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1749.5698 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1679.4819 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1612.4981 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1548.2731 - accuracy: 0.0181\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2444.7954 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 2287.2694 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 2163.6810 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 2060.1401 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1970.5181 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1889.7711 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1815.1580 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1745.0345 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1678.3805 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1614.3352 - accuracy: 0.0191\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2398.1942 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 2249.1755 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2129.7587 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 2028.8860 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1941.0569 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1860.9591 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1786.3422 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1716.0752 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1648.8363 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1584.3863 - accuracy: 0.0186\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2442.7634 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 2291.9131 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 2173.2200 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2073.4689 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1985.8775 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1905.9938 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1831.4920 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1761.0387 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1693.4238 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1628.6555 - accuracy: 0.0172\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2416.7108 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 114us/sample - loss: 2265.4988 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 2145.0890 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2043.9945 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1955.1601 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1873.9111 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1798.7166 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1727.5997 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1659.7014 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1594.5834 - accuracy: 0.0179\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2362.4688 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 2215.8998 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2100.8939 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 2003.7539 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1918.0386 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1838.9937 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1765.2370 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1695.4623 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 1629.0018 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1565.3107 - accuracy: 0.0179\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2251.5211 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 2132.0910 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 2030.9232 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1941.3136 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1859.9069 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1783.5784 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1711.2589 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1642.1074 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1575.7460 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1511.9495 - accuracy: 0.0181\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2533.3029 - accuracy: 0.0163\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 89us/sample - loss: 2358.6497 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 2222.9291 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2113.3849 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2018.9774 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1935.2338 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1857.9612 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1786.2416 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1718.1422 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1653.1951 - accuracy: 0.0163\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2382.2946 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 109us/sample - loss: 2237.7388 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 2121.0753 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2021.3664 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1934.6386 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1855.4276 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1781.3238 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1711.3812 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1644.8579 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1581.1543 - accuracy: 0.0184\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2339.3584 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 2200.8325 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 2086.5583 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1989.2454 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1902.7402 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1822.8282 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1747.9594 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1677.2455 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1609.8206 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1545.4577 - accuracy: 0.0165\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2360.2507 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 2224.9690 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 2111.9519 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 2014.0683 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1926.9413 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1846.3868 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1771.5695 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1700.2975 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1632.4135 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1567.5676 - accuracy: 0.0174\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2504.6998 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 2328.6283 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2193.3963 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 2085.5718 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1993.8889 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1912.5570 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1837.5209 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1767.4666 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1701.0570 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1637.0935 - accuracy: 0.0170\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2315.9416 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 2189.3665 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 2082.3902 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1989.4629 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1904.9494 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1826.4434 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1752.5448 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1682.1683 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1614.7241 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1549.9370 - accuracy: 0.0163\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2274.8027 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 2147.6092 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 2044.1891 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1955.0116 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1873.9972 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1798.3954 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1726.6756 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1658.1581 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1592.0722 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1528.6738 - accuracy: 0.0179\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2342.8466 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 2199.3980 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2085.7306 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1990.4693 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1906.1555 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1828.8260 - accuracy: 0.0184\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 78us/sample - loss: 1756.1120 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1687.1337 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1621.3016 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1558.1169 - accuracy: 0.0184\n",
      "It took 54.19 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(\n",
    "                    np.array(get_eigvec_of_laplacian(features[one_type_network]).flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(\n",
    "                    np.array(get_eigvec_of_laplacian(features[one_type_network]).flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim, 1),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            GlobalAveragePooling1D(),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(\n",
    "            np.reshape(flatten_X_train, (len(flatten_X_train), input_dim, 1)),\n",
    "            flatten_y_train,\n",
    "            epochs=10,\n",
    "            batch_size=64)\n",
    "        predicted = model.predict(np.reshape(flatten_X_test, (len(flatten_X_test), input_dim, 1)))\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6313814344667504 +- 0.01593418922224158\n",
      "uniform: 0.3464698770260923 +- 0.018411324177389537\n",
      "model: 0.3446204076260307 +- 0.01804294139729504\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5fc2e7518>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
