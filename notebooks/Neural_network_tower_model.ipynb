{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# Solve the estimation problem with neural network tower model on the supervised dataset from the Jeopardy-like logs\n",
    "# ===========================================================\n",
    "\n",
    "Goals:\n",
    "1. Split the data into test and train\n",
    "2. Formulate the neural network based model\n",
    "3. Compute train and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last update: 05 Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv1D, LSTM, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "from mytimer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = '/home/omid/Datasets/Jeopardy/supervised_data.pk'\n",
    "test_fraction = 0.2\n",
    "runs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix_err(true_matrix: np.matrix, pred_matrix: np.matrix, type_str: str = 'frob_norm') -> float:\n",
    "    if type_str == 'frob_norm':\n",
    "        frob_norm_of_difference = np.linalg.norm(true_matrix - pred_matrix)\n",
    "        err = frob_norm_of_difference / np.linalg.norm(true_matrix)\n",
    "        return err\n",
    "    elif type_str == 'corr':\n",
    "#         (r, p) = sp.stats.spearmanr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        (r, p) = sp.stats.pearsonr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        if p > 0.05:\n",
    "            r = 0\n",
    "        return r\n",
    "    else:\n",
    "        raise ValueError('Wrong type_str was given.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_it(data_fpath)\n",
    "print(len(data['X']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = []\n",
    "for i in range(len(data['y'])):\n",
    "    mats.append(data['y'][i]['influence_matrix'] / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26338279, 0.24830861, 0.25548961, 0.23243323],\n",
       "       [0.2189911 , 0.33845697, 0.2158457 , 0.2227003 ],\n",
       "       [0.21379822, 0.2511276 , 0.30367953, 0.22474777],\n",
       "       [0.25338279, 0.24091988, 0.24379822, 0.26367953]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12754406, 0.08032826, 0.09008641, 0.07827526],\n",
       "       [0.10004831, 0.19647938, 0.08964129, 0.11201212],\n",
       "       [0.09734972, 0.12308318, 0.17451618, 0.10372017],\n",
       "       [0.0940633 , 0.06791981, 0.06305615, 0.09161002]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mats, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulating the tower model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only content embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8295 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 127us/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7446 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7402 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7399 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7392 - accuracy: 0.0170\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8196 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7398 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7396 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7395 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7393 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7391 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7389 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7409 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7387 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7386 - accuracy: 0.0184\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8207 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7403 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7389 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7388 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7391 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7384 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7382 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7380 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8733 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 0.7400 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7384 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7382 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7381 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8236 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7402 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7419 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7399 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7398 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7397 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7396 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7394 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7393 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7391 - accuracy: 0.0172\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8319 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7412 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7402 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7398 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7397 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7392 - accuracy: 0.0170\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8697 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7419 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7405 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7404 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7402 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 103us/sample - loss: 0.7401 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7398 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7397 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7396 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7395 - accuracy: 0.0177\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8646 - accuracy: 0.0158\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7398 - accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7396 - accuracy: 0.0158\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7395 - accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7394 - accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7393 - accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7392 - accuracy: 0.0158\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7391 - accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7390 - accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7389 - accuracy: 0.0158\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8302 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7431 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7397 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7395 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7393 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7391 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7390 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7389 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 0.7389 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 0.7388 - accuracy: 0.0193\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8370 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7407 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7406 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7403 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7401 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7400 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7399 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7398 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7397 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8161 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7418 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7401 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7399 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7397 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7395 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7393 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7392 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7392 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7390 - accuracy: 0.0177\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8291 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7409 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7388 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7387 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7385 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7383 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7383 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7381 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7380 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7379 - accuracy: 0.0177\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8468 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.7406 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7394 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7391 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7390 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7389 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7388 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7387 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7386 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7385 - accuracy: 0.0184\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.9123 - accuracy: 0.0158\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7401 - accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7409 - accuracy: 0.0158\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7397 - accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7396 - accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7394 - accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7394 - accuracy: 0.0158\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7393 - accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7391 - accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 0.7391 - accuracy: 0.0158\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8879 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7445 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7412 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7401 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7400 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7399 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7398 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7397 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7396 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7395 - accuracy: 0.0181\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 6s 22ms/sample - loss: 0.8653 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7401 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7409 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7397 - accuracy: 0.0184\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7396 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7395 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7394 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7390 - accuracy: 0.0184\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8180 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7388 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7387 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7385 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7385 - accuracy: 0.0170\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8890 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7397 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7395 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7390 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7389 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7386 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7384 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7385 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7381 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7382 - accuracy: 0.0174\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8522 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7409 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7401 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7414 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7397 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7396 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7394 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7394 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7392 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7391 - accuracy: 0.0172\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8723 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7398 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7396 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7394 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7393 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7391 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7391 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7389 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7388 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7387 - accuracy: 0.0174\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8515 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.7393 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7403 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 0.7393 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7385 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7383 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7382 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7381 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7379 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7378 - accuracy: 0.0195\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8605 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7427 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7405 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7398 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8343 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 120us/sample - loss: 0.7432 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7397 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7388 - accuracy: 0.0170\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8245 - accuracy: 0.0195\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7411 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7397 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7397 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7400 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7391 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7389 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7387 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7386 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7386 - accuracy: 0.0195\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8389 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 118us/sample - loss: 0.7396 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7394 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7393 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7389 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7388 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7387 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7386 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7386 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7383 - accuracy: 0.0165\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8596 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7384 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7381 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7379 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7379 - accuracy: 0.0170\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8502 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7412 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7396 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7393 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7391 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7390 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7388 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7386 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7386 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7383 - accuracy: 0.0174\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8256 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7398 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7393 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7391 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7390 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7388 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7387 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7386 - accuracy: 0.0184\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.9384 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7411 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7406 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7405 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7402 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7399 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7399 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7397 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7395 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7394 - accuracy: 0.0195\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8299 - accuracy: 0.0158\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7424 - accuracy: 0.0160\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7413 - accuracy: 0.0160\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7411 - accuracy: 0.0160\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 0.7409 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7407 - accuracy: 0.0160\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7405 - accuracy: 0.0160\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 0.7404 - accuracy: 0.0160\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7404 - accuracy: 0.0160\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7402 - accuracy: 0.0160\n",
      "It took 35.49 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']            \n",
    "#             flatten_X_train.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_train.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "#             flatten_X_test.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_test.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu', input_shape=(3072,)),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(16, kernel_initializer='he_normal', activation='softmax')])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "#         model = Sequential([\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 input_shape=(3072,),\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=64,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=16,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='softmax',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1))\n",
    "#         ])\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.631026874981446 +- 0.013433107688312273\n",
      "uniform: 0.3504242268432317 +- 0.017263519200923328\n",
      "model: 0.34571035693852015 +- 0.016304089815225024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d76e66940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = True\n",
    "one_type_network = 'reply_duration'   # 'emotion_dominance'\n",
    "input_dim = 80\n",
    "lambda1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1158.2696 - accuracy: 0.1250\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 1092.7397 - accuracy: 0.1250\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 1030.5301 - accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 971.0058 - accuracy: 0.1250\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 914.2789 - accuracy: 0.1250\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 859.5781 - accuracy: 0.1250\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 807.3868 - accuracy: 0.1250\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 757.8414 - accuracy: 0.1250\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 710.2078 - accuracy: 0.1250\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 664.8851 - accuracy: 0.1250\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1152.4367 - accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1087.1442 - accuracy: 0.0625\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1025.2558 - accuracy: 0.0625\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 966.0087 - accuracy: 0.0625\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 909.1965 - accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 854.7026 - accuracy: 0.0625\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 802.8182 - accuracy: 0.0625\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 752.7122 - accuracy: 0.0625\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 705.1759 - accuracy: 0.0625\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 660.0195 - accuracy: 0.0625\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 1161.3533 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 1095.4645 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1032.9807 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 973.4399 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 915.6712 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 860.6667 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 808.2201 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 758.1944 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 710.0394 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 664.3931 - accuracy: 0.0000e+00\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1155.6255 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1091.5417 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1029.4901 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 970.1808 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 913.4522 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 858.6927 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 806.3557 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 756.4188 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 708.6250 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 663.1794 - accuracy: 0.0000e+00\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1173.8865 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1107.7343 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1045.2229 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 985.6119 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 927.7808 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 872.9427 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 819.9878 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 769.5198 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 721.1696 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 675.1249 - accuracy: 0.0000e+00\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1163.2359 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1098.9194 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1036.8690 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 977.3017 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 920.0761 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 865.4693 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 813.2571 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 762.9972 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 715.3236 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 669.4579 - accuracy: 0.0000e+00\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1176.3134 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1110.7229 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1048.8093 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 988.5113 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 930.6987 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 875.6725 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 822.6762 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 772.4468 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 724.0616 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 678.0568 - accuracy: 0.0000e+00\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1149.0164 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1084.4173 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1022.9652 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 66us/sample - loss: 963.8888 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 907.6850 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 853.1341 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 801.1838 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 751.2782 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 703.5175 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 658.1808 - accuracy: 0.0000e+00\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1173.7493 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1107.2034 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1043.9855 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 983.2108 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 925.5675 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 870.1696 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 817.8616 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 767.4616 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 719.4848 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 673.5755 - accuracy: 0.0000e+00\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1150.6726 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1086.2139 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1024.2535 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 964.3032 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 906.9597 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 851.6799 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 799.0244 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 748.6833 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 700.2788 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 654.0427 - accuracy: 0.0000e+00\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1150.4587 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1086.3353 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1024.3290 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 964.9894 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 908.3711 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 853.9637 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 801.9387 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 752.1656 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 704.5562 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 659.0616 - accuracy: 0.0000e+00\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1178.7010 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1112.0478 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1049.6494 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 989.2853 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 932.0926 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 877.4287 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 825.5202 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 775.9264 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 728.3482 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 683.0786 - accuracy: 0.0000e+00\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1165.3228 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 1099.6627 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1037.3309 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 977.8849 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 920.7886 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 865.9970 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 813.6995 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 763.3392 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 715.3678 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 669.4703 - accuracy: 0.0000e+00\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1163.2508 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 109us/sample - loss: 1097.3242 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1035.8386 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 976.3486 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 919.5337 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 865.1907 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 813.1472 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 763.3167 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 715.6048 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 669.9192 - accuracy: 0.0000e+00\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1142.8938 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1077.5734 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 1015.3831 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 956.2960 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 899.4194 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 845.3993 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 60us/sample - loss: 793.5151 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 744.0414 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 696.8208 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 652.1692 - accuracy: 0.0000e+00\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1151.3885 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1084.7052 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1021.7938 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 962.0848 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 904.8407 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 850.2406 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 798.1475 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 52us/sample - loss: 748.4586 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 700.7394 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 655.6127 - accuracy: 0.0000e+00\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1157.4743 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 1091.6315 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1027.8255 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 968.2789 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 910.7653 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 856.2084 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 803.6673 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 753.5034 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 705.9531 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 52us/sample - loss: 660.8537 - accuracy: 0.0000e+00\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1152.1656 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 1086.1894 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1022.9640 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 962.8727 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 905.3747 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 851.2540 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 798.8450 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 748.9073 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 701.5183 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 656.2279 - accuracy: 0.0000e+00\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1154.5585 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 1089.6649 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1027.5719 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 967.7907 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 911.4786 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 856.9336 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 805.1031 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 755.5737 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 708.0008 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 662.7348 - accuracy: 0.0000e+00\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1153.4302 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 1087.7681 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 1025.0527 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 965.1514 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 907.7560 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 852.7875 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 800.6139 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 750.4130 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 702.8886 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 657.8216 - accuracy: 0.0000e+00\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1149.6981 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 1084.6995 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1022.7502 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 962.7146 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 905.6858 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 850.8184 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 798.6362 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 748.6039 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 700.7929 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 655.4713 - accuracy: 0.0000e+00\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1163.2146 - accuracy: 0.2493\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1097.6479 - accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1034.6334 - accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 974.7484 - accuracy: 0.2500\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 917.0131 - accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 862.5082 - accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 809.5653 - accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 759.4155 - accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 711.9780 - accuracy: 0.2500\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 53us/sample - loss: 666.3411 - accuracy: 0.2500\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1149.2103 - accuracy: 0.2514\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1084.9285 - accuracy: 0.2502\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1023.0542 - accuracy: 0.2505\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 963.1736 - accuracy: 0.2502\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 906.3562 - accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 851.9677 - accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 799.8569 - accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 749.9202 - accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 702.5306 - accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 657.4243 - accuracy: 0.2500\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1164.8907 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1098.3793 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1035.5061 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 975.7613 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 918.0553 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 863.2400 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 810.5936 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 760.5025 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 712.5677 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 667.1220 - accuracy: 0.0000e+00\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1159.7830 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1095.6028 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1033.7282 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 974.1509 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 916.8116 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 861.8112 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 809.1630 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 758.9546 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 710.8782 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 664.8779 - accuracy: 0.0000e+00\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1131.8878 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 114us/sample - loss: 1066.7788 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1005.3389 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 945.9930 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 889.8189 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 835.6407 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 783.8887 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 734.2659 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 687.0531 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 642.1121 - accuracy: 0.0000e+00\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 7s 25ms/sample - loss: 1154.3701 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 1088.3991 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 1026.1702 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 965.5966 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 908.1575 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 853.3261 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 801.2209 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 751.4226 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 704.0188 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 658.6881 - accuracy: 0.0000e+00\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1158.1983 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1093.3993 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1029.8216 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 969.7403 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 911.8881 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 856.3546 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 803.5778 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 753.4222 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 705.5385 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 659.6961 - accuracy: 0.0000e+00\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1149.7991 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1085.4204 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1023.5732 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 964.0064 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 907.2255 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 852.7752 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 800.5453 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 750.5309 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 702.3081 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 656.6796 - accuracy: 0.0000e+00\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1157.3506 - accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1092.5662 - accuracy: 0.0625\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 72us/sample - loss: 1030.0847 - accuracy: 0.0625\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 970.2761 - accuracy: 0.0625\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 913.2369 - accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 858.2467 - accuracy: 0.0625\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 805.8099 - accuracy: 0.0625\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 755.3972 - accuracy: 0.0625\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 707.3408 - accuracy: 0.0625\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 661.5491 - accuracy: 0.0625\n",
      "It took 45.98 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim,),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=64,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6327249524274109 +- 0.017162693532443443\n",
      "uniform: 0.3533156935131415 +- 0.01815789146330699\n",
      "model: 0.3570876090926867 +- 0.017335393332607744\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d623d9518>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2900.0038 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 239us/sample - loss: 2480.0622 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 198us/sample - loss: 2234.6507 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 185us/sample - loss: 2053.1613 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 1903.8771 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 166us/sample - loss: 1773.2657 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1656.0913 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 161us/sample - loss: 1548.4245 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 172us/sample - loss: 1450.0813 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1358.4955 - accuracy: 0.0000e+00\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2504.8922 - accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 236us/sample - loss: 2210.6925 - accuracy: 0.0625\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 189us/sample - loss: 2004.9185 - accuracy: 0.0625\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 172us/sample - loss: 1843.0378 - accuracy: 0.0625\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 166us/sample - loss: 1705.4048 - accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 167us/sample - loss: 1583.8546 - accuracy: 0.0625\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 164us/sample - loss: 1473.7538 - accuracy: 0.0625\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 1372.2785 - accuracy: 0.0625\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1278.1022 - accuracy: 0.0625\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1189.9185 - accuracy: 0.0625\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3067.8362 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 256us/sample - loss: 2591.9053 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 2323.9273 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 187us/sample - loss: 2135.9532 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 1986.0803 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1857.4021 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1742.2150 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1637.3020 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1541.6278 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1453.3394 - accuracy: 0.0000e+00\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2956.7589 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 218us/sample - loss: 2491.3823 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 2221.3572 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 168us/sample - loss: 2032.6841 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1879.9189 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1750.2577 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1636.0980 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1533.3934 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1439.5592 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1353.0805 - accuracy: 0.0000e+00\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2955.6084 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 194us/sample - loss: 2539.2378 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 176us/sample - loss: 2285.3021 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 2102.9426 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 167us/sample - loss: 1955.6864 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1828.6206 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1714.4342 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1611.0503 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1515.7133 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1427.3250 - accuracy: 0.0000e+00\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2800.2953 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 229us/sample - loss: 2398.2232 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 2155.0049 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 1977.5540 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 1832.9654 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 166us/sample - loss: 1706.8261 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 168us/sample - loss: 1593.8509 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 161us/sample - loss: 1490.7198 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1395.1959 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1306.3170 - accuracy: 0.0000e+00\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2996.8285 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 248us/sample - loss: 2540.5777 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 2272.4765 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 2079.4545 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 166us/sample - loss: 1922.6257 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1790.0428 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1672.7013 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1566.1554 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1467.8338 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 172us/sample - loss: 1376.8134 - accuracy: 0.0000e+00\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2984.0027 - accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 220us/sample - loss: 2563.0324 - accuracy: 0.0625\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 189us/sample - loss: 2298.5910 - accuracy: 0.0625\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 2105.7033 - accuracy: 0.0625\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 163us/sample - loss: 1948.0514 - accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1813.2621 - accuracy: 0.0625\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1694.9948 - accuracy: 0.0625\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1587.6610 - accuracy: 0.0625\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1489.0325 - accuracy: 0.0625\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1397.7019 - accuracy: 0.0625\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2730.5065 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 2342.6788 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 2102.5133 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 168us/sample - loss: 1928.4947 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 163us/sample - loss: 1785.0868 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1660.3110 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1548.7901 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1446.7641 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1352.7314 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 164us/sample - loss: 1265.7295 - accuracy: 0.0000e+00\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3007.6934 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 229us/sample - loss: 2550.8508 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 192us/sample - loss: 2269.5445 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 170us/sample - loss: 2068.8104 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1908.5726 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1771.2643 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1650.7024 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1542.0505 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 1442.6057 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1351.4014 - accuracy: 0.0000e+00\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2919.0051 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 263us/sample - loss: 2536.2725 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 195us/sample - loss: 2283.3789 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 172us/sample - loss: 2089.1956 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 165us/sample - loss: 1929.1980 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1790.4943 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1665.8874 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 150us/sample - loss: 1553.1340 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1449.4033 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 149us/sample - loss: 1354.6542 - accuracy: 0.0000e+00\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3127.7964 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 2609.7002 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 2306.2121 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 2096.3281 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 1934.7059 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1799.4883 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 147us/sample - loss: 1681.1241 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 164us/sample - loss: 1574.3685 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1477.7009 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 166us/sample - loss: 1389.5127 - accuracy: 0.0000e+00\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3275.9610 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 201us/sample - loss: 2763.6627 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 2453.2086 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 163us/sample - loss: 2232.3631 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 161us/sample - loss: 2060.4013 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1913.3935 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1786.7491 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1672.7965 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1569.5696 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 147us/sample - loss: 1474.4039 - accuracy: 0.0000e+00\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2993.2564 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 199us/sample - loss: 2533.1101 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 2270.2038 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 2084.9791 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 1936.0205 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 167us/sample - loss: 1809.0314 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 164us/sample - loss: 1696.3063 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1593.4460 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 168us/sample - loss: 1498.9935 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1410.4903 - accuracy: 0.0000e+00\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3026.3413 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 223us/sample - loss: 2550.8794 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 197us/sample - loss: 2269.9253 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 165us/sample - loss: 2073.1048 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 153us/sample - loss: 1921.3828 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1793.0422 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1679.0925 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1575.6175 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 150us/sample - loss: 1480.2579 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 147us/sample - loss: 1392.4689 - accuracy: 0.0000e+00\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2766.5544 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 208us/sample - loss: 2394.7635 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 180us/sample - loss: 2165.0482 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 164us/sample - loss: 1992.9402 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 164us/sample - loss: 1850.8600 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1723.9658 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1609.2909 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 1504.2843 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1407.4334 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1317.4828 - accuracy: 0.0000e+00\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2824.9088 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 203us/sample - loss: 2418.8534 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 170us/sample - loss: 2163.3452 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 161us/sample - loss: 1980.9009 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1830.1569 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1701.6679 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 149us/sample - loss: 1586.9489 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 1484.0026 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1389.5314 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1302.6124 - accuracy: 0.0000e+00\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2707.7883 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 196us/sample - loss: 2346.2578 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 213us/sample - loss: 2118.7734 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 210us/sample - loss: 1947.7824 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 1805.1798 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 161us/sample - loss: 1680.1067 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1568.2108 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 1465.7541 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 150us/sample - loss: 1371.1059 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 145us/sample - loss: 1282.9260 - accuracy: 0.0000e+00\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2914.0146 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 2505.4875 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 2253.3738 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 2069.0807 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1917.7998 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1788.3242 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 1673.0097 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 1568.9187 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 1473.7997 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1385.9201 - accuracy: 0.0000e+00\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2799.0307 - accuracy: 0.1875\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 217us/sample - loss: 2414.1099 - accuracy: 0.1875\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 187us/sample - loss: 2169.8625 - accuracy: 0.1875\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 1985.9890 - accuracy: 0.1875\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 1835.8047 - accuracy: 0.1875\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1706.2369 - accuracy: 0.1875\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1591.4889 - accuracy: 0.1875\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1486.5216 - accuracy: 0.1875\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1389.6560 - accuracy: 0.1875\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1300.5834 - accuracy: 0.1875\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3150.7142 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 234us/sample - loss: 2665.3499 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 192us/sample - loss: 2370.7584 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 174us/sample - loss: 2157.8064 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1988.7572 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1845.1200 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 147us/sample - loss: 1718.0602 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 152us/sample - loss: 1604.5105 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 148us/sample - loss: 1501.6264 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1407.4848 - accuracy: 0.0000e+00\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 3075.1765 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 2608.2985 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 179us/sample - loss: 2331.7400 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 2135.2106 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 170us/sample - loss: 1976.6188 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1838.3765 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 166us/sample - loss: 1715.8793 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 167us/sample - loss: 1604.3191 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 164us/sample - loss: 1501.3767 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 163us/sample - loss: 1407.0368 - accuracy: 0.0000e+00\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 3290.0437 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 221us/sample - loss: 2735.5393 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 188us/sample - loss: 2430.8284 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 185us/sample - loss: 2221.8180 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 172us/sample - loss: 2060.3908 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 185us/sample - loss: 1923.2918 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 194us/sample - loss: 1803.0928 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 190us/sample - loss: 1694.4361 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 174us/sample - loss: 1594.5376 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 163us/sample - loss: 1502.6092 - accuracy: 0.0000e+00\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2995.5129 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 2539.3434 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 2266.5616 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 170us/sample - loss: 2068.4350 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 1910.6560 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1776.6917 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1658.2207 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1553.4520 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1458.5886 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 150us/sample - loss: 1371.8805 - accuracy: 0.0000e+00\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3077.7763 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 187us/sample - loss: 2592.3132 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 165us/sample - loss: 2319.3618 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 2126.3827 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 153us/sample - loss: 1974.3050 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 165us/sample - loss: 1844.0383 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1728.3984 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 1623.9705 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1527.3302 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1438.2256 - accuracy: 0.0000e+00\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2964.4852 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 209us/sample - loss: 2541.4456 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 183us/sample - loss: 2287.2869 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 2104.5794 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 168us/sample - loss: 1954.1195 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1824.2352 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 149us/sample - loss: 1709.0345 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1605.6915 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1512.5322 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 178us/sample - loss: 1426.4617 - accuracy: 0.0000e+00\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2538.2147 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 227us/sample - loss: 2261.5057 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 2066.1730 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 1907.6535 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 162us/sample - loss: 1769.5419 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1644.9544 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 155us/sample - loss: 1531.4055 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1426.0805 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1327.9155 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 156us/sample - loss: 1235.9918 - accuracy: 0.0000e+00\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2777.0979 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 193us/sample - loss: 2398.2112 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 186us/sample - loss: 2151.7996 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 177us/sample - loss: 1970.9637 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 172us/sample - loss: 1822.9165 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 1696.8525 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 1583.9879 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 1481.6056 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 169us/sample - loss: 1387.5133 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1300.5414 - accuracy: 0.0000e+00\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3089.1473 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 226us/sample - loss: 2601.2071 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 184us/sample - loss: 2318.9758 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 170us/sample - loss: 2118.6540 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 171us/sample - loss: 1958.4245 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 1823.1508 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1705.4309 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1600.2411 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 151us/sample - loss: 1506.3103 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1420.4970 - accuracy: 0.0000e+00\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 3014.5148 - accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 207us/sample - loss: 2573.5614 - accuracy: 0.0625\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 182us/sample - loss: 2297.4286 - accuracy: 0.0625\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 173us/sample - loss: 2096.6011 - accuracy: 0.0625\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 160us/sample - loss: 1936.0270 - accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 158us/sample - loss: 1798.0222 - accuracy: 0.0625\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1676.9092 - accuracy: 0.0625\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 154us/sample - loss: 1568.2812 - accuracy: 0.0625\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 157us/sample - loss: 1468.3499 - accuracy: 0.0625\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 159us/sample - loss: 1376.6441 - accuracy: 0.0625\n",
      "It took 1.00 minutes.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim, 1),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            GlobalAveragePooling1D(),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(np.reshape(flatten_X_train, (len(flatten_X_train), 80, 1)), flatten_y_train, epochs=10, batch_size=32)\n",
    "        predicted = model.predict(np.reshape(flatten_X_test, (len(flatten_X_test), 80, 1)))\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6356258097493976 +- 0.013100026143269097\n",
      "uniform: 0.34841464847640174 +- 0.015601739269169973\n",
      "model: 0.3536262330466194 +- 0.015643277966374127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d438a0c88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
