{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# Solve the estimation problem with neural network tower model on the supervised dataset from the Jeopardy-like logs\n",
    "# ===========================================================\n",
    "\n",
    "Goals:\n",
    "1. Split the data into test and train\n",
    "2. Formulate the neural network based model\n",
    "3. Compute train and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last update: 05 Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv1D, LSTM, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "from mytimer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = '/home/omid/Datasets/Jeopardy/supervised_data.pk'\n",
    "test_fraction = 0.2\n",
    "runs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix_err(true_matrix: np.matrix, pred_matrix: np.matrix, type_str: str = 'frob_norm') -> float:\n",
    "    if type_str == 'frob_norm':\n",
    "        frob_norm_of_difference = np.linalg.norm(true_matrix - pred_matrix)\n",
    "        err = frob_norm_of_difference / np.linalg.norm(true_matrix)\n",
    "        return err\n",
    "    elif type_str == 'corr':\n",
    "#         (r, p) = sp.stats.spearmanr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        (r, p) = sp.stats.pearsonr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        if p > 0.05:\n",
    "            r = 0\n",
    "        return r\n",
    "    else:\n",
    "        raise ValueError('Wrong type_str was given.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eigvec_of_laplacian(A: np.matrix) -> np.matrix:\n",
    "#     D = np.diag(np.array(np.sum(A, axis=0))[0])\n",
    "#     L = D - A\n",
    "#     return np.matrix(np.linalg.eig(L)[1])\n",
    "    n, m = A.shape\n",
    "    diags = A.sum(axis=1).flatten()\n",
    "    D = sp.sparse.spdiags(diags, [0], m, n, format='csr')\n",
    "    L = D - A\n",
    "    with sp.errstate(divide='ignore'):\n",
    "        diags_sqrt = 1.0/sp.sqrt(diags)\n",
    "    diags_sqrt[sp.isinf(diags_sqrt)] = 0\n",
    "    DH = sp.sparse.spdiags(diags_sqrt, [0], m, n, format='csr')\n",
    "    DH = DH.todense()\n",
    "    normalized_L = DH.dot(L.dot(DH))\n",
    "    return normalized_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_it(data_fpath)\n",
    "print(len(data['X']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = []\n",
    "for i in range(len(data['y'])):\n",
    "    mats.append(data['y'][i]['influence_matrix'] / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26338279, 0.24830861, 0.25548961, 0.23243323],\n",
       "       [0.2189911 , 0.33845697, 0.2158457 , 0.2227003 ],\n",
       "       [0.21379822, 0.2511276 , 0.30367953, 0.22474777],\n",
       "       [0.25338279, 0.24091988, 0.24379822, 0.26367953]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12754406, 0.08032826, 0.09008641, 0.07827526],\n",
       "       [0.10004831, 0.19647938, 0.08964129, 0.11201212],\n",
       "       [0.09734972, 0.12308318, 0.17451618, 0.10372017],\n",
       "       [0.0940633 , 0.06791981, 0.06305615, 0.09161002]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mats, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulating the tower model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only content embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8295 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 127us/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7446 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7402 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7399 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7392 - accuracy: 0.0170\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8196 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7398 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7396 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7395 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7393 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7391 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7389 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7409 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7387 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7386 - accuracy: 0.0184\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8207 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7403 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7389 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7388 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7391 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7384 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7382 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7380 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8733 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 0.7400 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7384 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7382 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7381 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8236 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7402 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7419 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7399 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7398 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7397 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7396 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7394 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7393 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7391 - accuracy: 0.0172\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8319 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7412 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7402 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7398 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7397 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7392 - accuracy: 0.0170\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8697 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7419 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7405 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7404 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7402 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 103us/sample - loss: 0.7401 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7398 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7397 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7396 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7395 - accuracy: 0.0177\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8646 - accuracy: 0.0158\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7398 - accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7396 - accuracy: 0.0158\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7395 - accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7394 - accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7393 - accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7392 - accuracy: 0.0158\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7391 - accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7390 - accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7389 - accuracy: 0.0158\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8302 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7431 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7397 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7395 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7393 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7391 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7390 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7389 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 0.7389 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 0.7388 - accuracy: 0.0193\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8370 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7407 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7406 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7403 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7401 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7400 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7399 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7398 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7397 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8161 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7418 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7401 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7399 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7397 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7395 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7393 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7392 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7392 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7390 - accuracy: 0.0177\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8291 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7409 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7388 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7387 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7385 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7383 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7383 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7381 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7380 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7379 - accuracy: 0.0177\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8468 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.7406 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7394 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7391 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7390 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7389 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7388 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7387 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7386 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7385 - accuracy: 0.0184\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.9123 - accuracy: 0.0158\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7401 - accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7409 - accuracy: 0.0158\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7397 - accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7396 - accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7394 - accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7394 - accuracy: 0.0158\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7393 - accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7391 - accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 0.7391 - accuracy: 0.0158\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8879 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7445 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7412 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7401 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7400 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7399 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7398 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7397 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7396 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7395 - accuracy: 0.0181\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 6s 22ms/sample - loss: 0.8653 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7401 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7409 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7397 - accuracy: 0.0184\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7396 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7395 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7394 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7390 - accuracy: 0.0184\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8180 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7388 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7387 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7385 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7385 - accuracy: 0.0170\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8890 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7397 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7395 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7390 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7389 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7386 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7384 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7385 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7381 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7382 - accuracy: 0.0174\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8522 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7409 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7401 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7414 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7397 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7396 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7394 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7394 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7392 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7391 - accuracy: 0.0172\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8723 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7398 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7396 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7394 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7393 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7391 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7391 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7389 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7388 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7387 - accuracy: 0.0174\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8515 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 121us/sample - loss: 0.7393 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7403 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 0.7393 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7385 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7383 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7382 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7381 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7379 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7378 - accuracy: 0.0195\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8605 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7427 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7405 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7398 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8343 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 120us/sample - loss: 0.7432 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7397 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7394 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7393 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7388 - accuracy: 0.0170\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8245 - accuracy: 0.0195\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7411 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7397 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7397 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7400 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7391 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7389 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7387 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7386 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7386 - accuracy: 0.0195\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8389 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 118us/sample - loss: 0.7396 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7394 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7393 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7389 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7388 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7387 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7386 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7386 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7383 - accuracy: 0.0165\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8596 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7395 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7384 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7381 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7379 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7379 - accuracy: 0.0170\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.8502 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 102us/sample - loss: 0.7412 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7396 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7393 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7391 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7390 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7388 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7386 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7386 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7383 - accuracy: 0.0174\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8256 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7398 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7393 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7391 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7390 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7392 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7388 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7387 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7386 - accuracy: 0.0184\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.9384 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7411 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7406 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7405 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7402 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7399 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7399 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7397 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7395 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7394 - accuracy: 0.0195\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.8299 - accuracy: 0.0158\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7424 - accuracy: 0.0160\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7413 - accuracy: 0.0160\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7411 - accuracy: 0.0160\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 0.7409 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7407 - accuracy: 0.0160\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7405 - accuracy: 0.0160\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 0.7404 - accuracy: 0.0160\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7404 - accuracy: 0.0160\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7402 - accuracy: 0.0160\n",
      "It took 35.49 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']            \n",
    "#             flatten_X_train.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_train.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "#             flatten_X_test.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_test.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu', input_shape=(3072,)),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(16, kernel_initializer='he_normal', activation='softmax')])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "#         model = Sequential([\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 input_shape=(3072,),\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=64,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=16,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='softmax',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1))\n",
    "#         ])\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.631026874981446 +- 0.013433107688312273\n",
      "uniform: 0.3504242268432317 +- 0.017263519200923328\n",
      "model: 0.34571035693852015 +- 0.016304089815225024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d76e66940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = True\n",
    "one_type_network = 'reply_duration'   # 'emotion_dominance'\n",
    "input_dim = 80\n",
    "lambda1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1129.2028 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 1064.8313 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1003.3088 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 944.0386 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 888.0018 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 834.2492 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 782.8130 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 733.7862 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 686.8196 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 642.0795 - accuracy: 0.0181\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1139.9742 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1075.5409 - accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1014.2850 - accuracy: 0.0158\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 954.9360 - accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 898.0919 - accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 843.4122 - accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 791.3481 - accuracy: 0.0158\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 741.4664 - accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 693.7342 - accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 648.2541 - accuracy: 0.0158\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1155.9748 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1090.9233 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1029.0111 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 968.2999 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 910.9342 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 856.2688 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 803.3710 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 752.9869 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 704.5878 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 658.8891 - accuracy: 0.0167\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1166.2186 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1100.8335 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1039.0170 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 979.6093 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 922.9814 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 869.0565 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 816.9134 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 767.2183 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 719.6365 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 674.2045 - accuracy: 0.0193\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1144.1854 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 1079.3233 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1017.7338 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 958.4422 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 901.5538 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 847.4018 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 795.4554 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 745.5239 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 698.0062 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 652.8114 - accuracy: 0.0156\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1156.1080 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1090.5628 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 1028.1691 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 968.5407 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 911.9006 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 857.6487 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 805.6659 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 756.2174 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 708.9602 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 663.9904 - accuracy: 0.0167\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1143.5085 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1078.5653 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1016.2720 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 957.1737 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 900.0817 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 845.5307 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 793.4327 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 743.6954 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 696.2274 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 651.1582 - accuracy: 0.0167\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1159.9867 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1096.0405 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1033.7801 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 974.1174 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 916.7466 - accuracy: 0.0177\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 75us/sample - loss: 862.4249 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 810.4289 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 760.2302 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 712.5842 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 667.2200 - accuracy: 0.0177\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1177.5967 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 1112.2172 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1049.9725 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 989.7653 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 931.7611 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 876.5170 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 823.5754 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 772.8690 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 724.5442 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 678.4924 - accuracy: 0.0165\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1173.5135 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1108.9259 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1046.7414 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 987.3347 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 929.5036 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 874.5877 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 821.9335 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 771.0937 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 722.9175 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 676.6407 - accuracy: 0.0179\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1148.4148 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1083.7283 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 1021.9998 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 963.2463 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 907.0173 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 852.7526 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 801.2573 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 751.7239 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 704.4360 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 659.2564 - accuracy: 0.0177\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1166.1102 - accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1100.7097 - accuracy: 0.0188\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1037.8269 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 977.7264 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 920.4520 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 865.4415 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 813.2466 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 763.0242 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 715.1081 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 669.3643 - accuracy: 0.0188\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1140.4614 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1074.4964 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1013.3498 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 953.7008 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 896.8580 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 842.7106 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 790.7675 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 741.4915 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 694.4414 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 649.8993 - accuracy: 0.0177\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1171.5424 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1107.0800 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1045.5637 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 986.0753 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 928.6300 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 873.6497 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 821.0766 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 770.7407 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 722.5543 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 676.6280 - accuracy: 0.0193\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1146.3331 - accuracy: 0.0153\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1081.2212 - accuracy: 0.0153\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1019.7446 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 960.3851 - accuracy: 0.0153\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 903.4525 - accuracy: 0.0153\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 848.9426 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 796.4592 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 746.7560 - accuracy: 0.0153\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 699.3042 - accuracy: 0.0153\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 654.3406 - accuracy: 0.0153\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 3ms/sample - loss: 1135.1535 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 1071.0275 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 1008.8973 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 949.9622 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 892.7380 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 838.4916 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 786.4447 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 736.9422 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 689.7770 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 644.7653 - accuracy: 0.0181\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1161.7091 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1095.6503 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1033.5331 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 973.4751 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 916.1235 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 861.1882 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 809.0379 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 759.1021 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 711.4668 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 665.8519 - accuracy: 0.0167\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.4299 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1083.3459 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1021.4114 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 962.3643 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 905.9802 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 852.0611 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 800.2745 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 751.0585 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 704.2451 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 659.3552 - accuracy: 0.0177\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1156.1761 - accuracy: 0.0153\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1091.2596 - accuracy: 0.0153\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1028.8294 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 968.9954 - accuracy: 0.0153\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 911.8857 - accuracy: 0.0153\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 857.2292 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 805.2266 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 755.4080 - accuracy: 0.0153\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 707.9492 - accuracy: 0.0153\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 662.5152 - accuracy: 0.0153\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1148.6885 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1083.5594 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1021.5588 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 962.2911 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 905.5994 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 851.2257 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 799.3261 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 749.3376 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 701.6837 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 656.0672 - accuracy: 0.0195\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1171.1398 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1104.9599 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1041.6840 - accuracy: 0.0197\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 981.1663 - accuracy: 0.0197\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 924.3704 - accuracy: 0.0197\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 869.1978 - accuracy: 0.0197\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 816.4479 - accuracy: 0.0197\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 766.0721 - accuracy: 0.0197\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 717.7793 - accuracy: 0.0197\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 672.2426 - accuracy: 0.0197\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.1805 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1083.1277 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1021.2257 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 961.9440 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 905.2668 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 850.9572 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 798.9083 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 749.1899 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 701.9336 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 656.7258 - accuracy: 0.0179\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1132.1559 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1066.4077 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1004.7243 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 945.1560 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 888.2962 - accuracy: 0.0193\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 61us/sample - loss: 833.9246 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 781.9596 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 732.5152 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 685.9425 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 641.3913 - accuracy: 0.0193\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1159.1377 - accuracy: 0.0160\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1093.9618 - accuracy: 0.0160\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1031.2505 - accuracy: 0.0160\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 971.9063 - accuracy: 0.0160\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 914.4294 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 859.8280 - accuracy: 0.0160\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 807.2810 - accuracy: 0.0160\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 756.9763 - accuracy: 0.0160\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 709.1444 - accuracy: 0.0160\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 663.4555 - accuracy: 0.0160\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1138.2437 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1072.4098 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1010.2879 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 950.3695 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 893.7916 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 839.6181 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 787.5018 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 738.4247 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 691.2649 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 646.4815 - accuracy: 0.0167\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1153.9272 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1088.6069 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1027.2105 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 967.5574 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 910.1670 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 855.7661 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 803.7105 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 753.9431 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 706.4912 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 661.3029 - accuracy: 0.0167\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1154.9127 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1089.9382 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1027.5484 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 967.5648 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 909.7255 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 855.2228 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 802.2617 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 752.1714 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 704.3723 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 658.7658 - accuracy: 0.0186\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1157.7748 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1091.6244 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 1028.9416 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 968.7104 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 911.3704 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 856.3421 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 803.3847 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 753.3710 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 705.7298 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 660.5937 - accuracy: 0.0188\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1148.1463 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1083.3388 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1021.8961 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 961.9822 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 905.4330 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 850.8270 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 798.6586 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 748.8168 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 701.3088 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 655.8904 - accuracy: 0.0177\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.6232 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1082.2249 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 1020.0382 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 960.7634 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 903.7219 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 849.2745 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 797.2047 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 747.3739 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 699.9482 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 654.8754 - accuracy: 0.0163\n",
      "It took 40.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim,),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=64,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6310301214868926 +- 0.01399059267030896\n",
      "uniform: 0.34745737869634064 +- 0.017530337002096035\n",
      "model: 0.34513695020571783 +- 0.016975889090539077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc547f7feb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = False\n",
    "one_type_network = 'reply_duration'   # 'emotion_dominance'\n",
    "input_dim = 16\n",
    "lambda1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/omid/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "269/269 [==============================] - 1s 5ms/sample - loss: 2316.7463 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 2183.4574 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2074.5713 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1979.9266 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1894.4858 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1815.4952 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1741.3955 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1670.9995 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1603.6196 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1538.9773 - accuracy: 0.0184\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2450.9399 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 119us/sample - loss: 2292.4517 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 2168.4721 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 2066.5708 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1977.8607 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1898.1154 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1823.4210 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1752.8025 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1685.1384 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1620.7432 - accuracy: 0.0179\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2388.0205 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 2243.4778 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2128.1227 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 2029.5754 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1941.9750 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1861.2338 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1786.0395 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1714.7197 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1646.9767 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1581.9344 - accuracy: 0.0193\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2356.2360 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2220.3267 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2108.4744 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 2011.7390 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 1925.9535 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 1847.0319 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1773.0010 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1702.9753 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1635.7740 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1571.1784 - accuracy: 0.0193\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2396.6715 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 2251.2056 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 2135.9138 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2039.7016 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1954.8239 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1877.0427 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1804.3667 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1735.2998 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1669.0223 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1605.4971 - accuracy: 0.0174\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2299.3032 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2177.2090 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 2073.8609 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1982.6824 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1899.5181 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1821.7955 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1748.2063 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1677.9813 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1610.5383 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1545.2336 - accuracy: 0.0167\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2324.0501 - accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 2191.6380 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2083.0006 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1989.2089 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1904.8294 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1826.9468 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1753.7523 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1684.2394 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1617.6341 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1553.8183 - accuracy: 0.0191\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2520.4810 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 2349.8472 - accuracy: 0.0179\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 70us/sample - loss: 2214.7773 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 2104.7400 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 2009.7255 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1925.4602 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1847.6449 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1774.8255 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1705.8209 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1640.4519 - accuracy: 0.0179\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2438.2959 - accuracy: 0.0151\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 2283.4382 - accuracy: 0.0151\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 2160.7340 - accuracy: 0.0151\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2058.2293 - accuracy: 0.0151\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 1969.8852 - accuracy: 0.0151\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1889.2356 - accuracy: 0.0151\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1814.1718 - accuracy: 0.0151\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1743.4460 - accuracy: 0.0151\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1675.9860 - accuracy: 0.0151\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1611.2421 - accuracy: 0.0151\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2363.5804 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 2229.2374 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2120.4864 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 2026.8631 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1942.4040 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1864.1887 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1790.6089 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1720.2925 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1653.1304 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1588.7999 - accuracy: 0.0177\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2431.8131 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 2284.1098 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 2164.9821 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 2064.0368 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1974.6460 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1892.4672 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1816.2226 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1744.0807 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1675.4689 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1609.5355 - accuracy: 0.0156\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2323.8424 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 2197.3442 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2090.5687 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1997.5349 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1912.9364 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1833.8643 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1759.3569 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1688.2503 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1620.5883 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1555.3995 - accuracy: 0.0177\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2312.5504 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 2175.7793 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 2065.1662 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1970.4899 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1886.3214 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1808.7453 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1735.9351 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1666.7718 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1600.5467 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1536.9825 - accuracy: 0.0167\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2329.6424 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2196.4774 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 2087.3506 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 1992.3061 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 1907.2527 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1828.4540 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1754.2159 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1683.4406 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1615.6550 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1550.4778 - accuracy: 0.0193\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2407.5517 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 2255.0614 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2134.0168 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 2032.2323 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1942.8927 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1861.9991 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1786.6767 - accuracy: 0.0174\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 77us/sample - loss: 1715.8591 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1648.2367 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1583.3526 - accuracy: 0.0174\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2326.9215 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 2192.6564 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 2081.9460 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1986.5235 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 1901.4864 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1823.1826 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1749.5698 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1679.4819 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1612.4981 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1548.2731 - accuracy: 0.0181\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2444.7954 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 2287.2694 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 2163.6810 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 2060.1401 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1970.5181 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 1889.7711 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1815.1580 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1745.0345 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1678.3805 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1614.3352 - accuracy: 0.0191\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2398.1942 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 2249.1755 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2129.7587 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 2028.8860 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1941.0569 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1860.9591 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1786.3422 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1716.0752 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1648.8363 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1584.3863 - accuracy: 0.0186\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2442.7634 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 2291.9131 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 2173.2200 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2073.4689 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1985.8775 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1905.9938 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1831.4920 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1761.0387 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1693.4238 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1628.6555 - accuracy: 0.0172\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2416.7108 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 114us/sample - loss: 2265.4988 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 2145.0890 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2043.9945 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1955.1601 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1873.9111 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1798.7166 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1727.5997 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1659.7014 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1594.5834 - accuracy: 0.0179\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2362.4688 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 2215.8998 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2100.8939 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 2003.7539 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1918.0386 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1838.9937 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1765.2370 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1695.4623 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 1629.0018 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1565.3107 - accuracy: 0.0179\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2251.5211 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 2132.0910 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 2030.9232 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1941.3136 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1859.9069 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1783.5784 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1711.2589 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1642.1074 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1575.7460 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1511.9495 - accuracy: 0.0181\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2533.3029 - accuracy: 0.0163\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 89us/sample - loss: 2358.6497 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 2222.9291 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 2113.3849 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 2018.9774 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1935.2338 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1857.9612 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1786.2416 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1718.1422 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1653.1951 - accuracy: 0.0163\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2382.2946 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 109us/sample - loss: 2237.7388 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 2121.0753 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 2021.3664 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1934.6386 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1855.4276 - accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1781.3238 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1711.3812 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1644.8579 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1581.1543 - accuracy: 0.0184\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2339.3584 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 2200.8325 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 2086.5583 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1989.2454 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1902.7402 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1822.8282 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1747.9594 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 1677.2455 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1609.8206 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 1545.4577 - accuracy: 0.0165\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2360.2507 - accuracy: 0.0174\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 2224.9690 - accuracy: 0.0174\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 2111.9519 - accuracy: 0.0174\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 2014.0683 - accuracy: 0.0174\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1926.9413 - accuracy: 0.0174\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1846.3868 - accuracy: 0.0174\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1771.5695 - accuracy: 0.0174\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1700.2975 - accuracy: 0.0174\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1632.4135 - accuracy: 0.0174\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1567.5676 - accuracy: 0.0174\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2504.6998 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 2328.6283 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 2193.3963 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 2085.5718 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1993.8889 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 1912.5570 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1837.5209 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1767.4666 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1701.0570 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1637.0935 - accuracy: 0.0170\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2315.9416 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 2189.3665 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 2082.3902 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1989.4629 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1904.9494 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1826.4434 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1752.5448 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1682.1683 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1614.7241 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1549.9370 - accuracy: 0.0163\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 2274.8027 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 2147.6092 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 2044.1891 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1955.0116 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 1873.9972 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1798.3954 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1726.6756 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1658.1581 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1592.0722 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 1528.6738 - accuracy: 0.0179\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 2342.8466 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 2199.3980 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 2085.7306 - accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1990.4693 - accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1906.1555 - accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1828.8260 - accuracy: 0.0184\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 78us/sample - loss: 1756.1120 - accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1687.1337 - accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1621.3016 - accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 1558.1169 - accuracy: 0.0184\n",
      "It took 54.19 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(\n",
    "                    np.array(get_eigvec_of_laplacian(features[one_type_network]).flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(\n",
    "                    np.array(get_eigvec_of_laplacian(features[one_type_network]).flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0] / 100)\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim, 1),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            GlobalAveragePooling1D(),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(\n",
    "            np.reshape(flatten_X_train, (len(flatten_X_train), input_dim, 1)),\n",
    "            flatten_y_train,\n",
    "            epochs=10,\n",
    "            batch_size=64)\n",
    "        predicted = model.predict(np.reshape(flatten_X_test, (len(flatten_X_test), input_dim, 1)))\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix'] / 100\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6313814344667504 +- 0.01593418922224158\n",
      "uniform: 0.3464698770260923 +- 0.018411324177389537\n",
      "model: 0.3446204076260307 +- 0.01804294139729504\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEqtJREFUeJzt3X2QXXV9x/H3lySwEgFpsjiYuOzSITyEYIJLtAJKyUDVKE/W4VGg1AnMtB212AKVkdBxsHWYFh0ZOhkrohKhPM10QLRCYQKMAklYY2JCJ+Aii7aBjRVBE93w7R97E5d0k73Ze+7e+1ver5mdnHPvued87tnkk7O/c87dyEwkSeXYq9UBJEl7xuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFWZqM1Y6c+bM7O7ubsaqJWlSWrVq1UuZ2VnPsk0p7u7ublauXNmMVUvSpBQRz9W7rEMlklQYi1uSCmNxS1JhmjLGLemN53e/+x0DAwNs2bKl1VHaWkdHB7Nnz2batGnjXofFLakSAwMD7LfffnR3dxMRrY7TljKTwcFBBgYG6OnpGfd6xhwqiYjDI6JvxNfLEfHJcW9R0qS0ZcsWZsyYYWnvRkQwY8aMhn8qGfOIOzOfBubXNjoFeAG4p6GtSpqULO2xVbGP9vTk5CLgmcys+3pDSVK19nSM+xzgW80IImly6b7yvkrX1/8Piytd31i230g4c+bMhpZphrqLOyL2Bk4DrtrF80uAJQBdXV2VhJOaYukBrU4w8Zb+stUJVKE9GSr5ALA6M/9ntCczc1lm9mZmb2dnXbfbS1Kl+vv7OeKII7j44ouZM2cO559/Pg888ADHH388hx12GE888QSbN2/mjDPO4JhjjuHd7343a9asAWBwcJBTTz2VuXPn8vGPf5zM3LHeb37zmyxcuJD58+dz6aWXsm3btla9RWDPivtcHCaR1OY2btzI5ZdfzoYNG9iwYQPLly/n0Ucf5frrr+e6667jmmuuYcGCBaxZs4brrruOCy+8EIBrr72WE044gXXr1nHmmWfy05/+FID169dz++2389hjj9HX18eUKVO49dZbW/kW6xsqiYjpwCnApc2NI0mN6enpYd68eQDMnTuXRYsWERHMmzeP/v5+nnvuOe666y4ATj75ZAYHB3n55ZdZsWIFd999NwCLFy/mwAMPBODBBx9k1apVHHfccQD85je/4aCDDmrBO/u9uoo7M18FZjQ5iyQ1bJ999tkxvddee+2Y32uvvRgaGtrjOxYzk4suuojPf/7zleZshJ9VIukN5cQTT9wx1PHwww8zc+ZM9t9/f9773veyfPlyAO6//35+8YtfALBo0SLuvPNONm3aBMDmzZt57rnWXhHtLe+SmmKiL9+r19KlS7nkkks45phj2HfffbnlllsAuOaaazj33HOZO3cu73nPe3ZcHXfUUUfxuc99jlNPPZXXXnuNadOmceONN3LIIYe07D3EyDOnVent7U1/kYLalpcDNsX69es58sgjm76dyWC0fRURqzKzt57XO1QiSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCuN13JKao+rLLptwSePKlSv5+te/zpe+9CW2bt3K4sWLeemll7jqqqs4++yzK99eVSxuSW9Yvb299PYOXzr91FNPAdDX11f367dt28aUKVOakm13HCqRNGn09/dz9NFH75i//vrrWbp0KSeddBJXXHEFCxcuZM6cOTzyyCPA8C3vH/rQh9i0aRMXXHABTz75JPPnz+eZZ57hwQcfZMGCBcybN49LLrmErVu3AsO/POGKK67g2GOP5Y477uCkk07iU5/6FL29vRx55JE8+eSTnHXWWRx22GFcffXVTXmfFrekN4ShoSGeeOIJbrjhBq699trXPXfQQQfxla98hRNPPJG+vj5mzZrFxRdfzO23386PfvQjhoaGuOmmm3YsP2PGDFavXs0555wDwN57783KlSu57LLLOP3007nxxhtZu3YtX/va1xgcHKz8vVjckt4QzjrrLADe+c530t/fv9tln376aXp6epgzZw4AF110EStWrNjx/M7j36eddhoA8+bNY+7cuRx88MHss88+HHrooTz//PMVvothFrekSWPq1Km89tprO+a3bNmyY3r7x7tOmTKFoaGhhrYzffr0182P/OjYnT9WttFtjcbiljRpvPWtb2XTpk0MDg6ydetW7r333nGt5/DDD6e/v5+NGzcC8I1vfIP3ve99VUZtiFeVSGqOFvyC4mnTpvHZz36WhQsXMmvWLI444ohxraejo4Obb76Zj370owwNDXHcccdx2WWXVZx2/PxYV73x+LGuTeHHutbPj3WVpDcYi1uSCmNxS6pMM4ZeJ5sq9lFdxR0Rb4mIOyNiQ0Ssj4g/anjLkiaVjo4OBgcHLe/dyEwGBwfp6OhoaD31XlXyReA7mfmnEbE3sG9DW5U06cyePZuBgQFefPHFVkdpax0dHcyePbuhdYxZ3BFxAPBe4GKAzPwt8NuGtipp0pk2bRo9PT2tjvGGUM8Rdw/wInBzRLwDWAV8IjNfHblQRCwBlgA7fq291GrdV973/x7rb+ynVKnl6hnjngocC9yUmQuAV4Erd14oM5dlZm9m9nZ2dlYcU5K0XT3FPQAMZObjtfk7GS5ySVILjFncmfnfwPMRcXjtoUXAj5uaSpK0S/VeVfJXwK21K0qeBf6seZEkSbtTV3FnZh9Q1z30kqTm8s5JSSqMxS1JhbG4JakwFrckFcbilqTCWNySVBiLW5IKY3FLUmEsbkkqjMUtSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1JhLG5JKozFLUmFsbglqTAWtyQVpq5fFhwR/cCvgG3AUGb6i4MlqUXqKu6aP87Ml5qWRJJUF4dKJKkw9RZ3Av8REasiYkkzA0mSdq/eoZITMvOFiDgI+F5EbMjMFSMXqBX6EoCurq6KY0pqyNIDWrTdX7Zmu5NcXUfcmflC7c9NwD3AwlGWWZaZvZnZ29nZWW1KSdIOYxZ3REyPiP22TwOnAmubHUySNLp6hkreCtwTEduXX56Z32lqKknSLo1Z3Jn5LPCOCcgiSaqDlwNKUmEsbkkqjMUtSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1JhLG5JKozFLUmFsbglqTAWtyQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFabu4o6IKRHxVETc28xAkqTd25Mj7k8A65sVRJJUn7qKOyJmA4uBrzQ3jiRpLPUecd8A/C3w2q4WiIglEbEyIla++OKLlYSTJP1/YxZ3RHwI2JSZq3a3XGYuy8zezOzt7OysLKAk6fXqOeI+HjgtIvqB24CTI+KbTU0lSdqlMYs7M6/KzNmZ2Q2cA/xnZl7Q9GSSpFF5HbckFWbqniycmQ8DDzcliSSpLh5xS1JhLG5JKozFLUmFsbglqTAWtyQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFcbilqTCWNySVBiLW5IKY3FLUmEsbkkqjMUtSYWxuCWpMGMWd0R0RMQTEfHDiFgXEddORDBJ0ujq+S3vW4GTM/OViJgGPBoR92fmD5qcTZI0ijGLOzMTeKU2O632lc0MJUnatbrGuCNiSkT0AZuA72Xm482NJUnalXqGSsjMbcD8iHgLcE9EHJ2Za0cuExFLgCUAXV1dlQedjLqvvO918/0d57UmyNJftma7ksZlj64qycz/BR4C3j/Kc8syszczezs7O6vKJ0naST1XlXTWjrSJiDcBpwAbmh1MkjS6eoZKDgZuiYgpDBf9v2Xmvc2NJUnalXquKlkDLJiALJKkOnjnpCQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFcbilqTCWNySVBiLW5IKY3FLUmEsbkkqjMUtSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1JhxizuiHh7RDwUET+OiHUR8YmJCCZJGt3UOpYZAi7PzNURsR+wKiK+l5k/bnI2SdIoxjzizsyfZ+bq2vSvgPXArGYHkySNbo/GuCOiG1gAPN6MMJKksdUzVAJARLwZuAv4ZGa+PMrzS4AlAF1dXeMO1H3lfTum+zvOG/d6GrL0l63ZbqssPaAlm+3esrwl29XkMLIrdjbZu6OuI+6ImMZwad+amXePtkxmLsvM3szs7ezsrDKjJGmEeq4qCeBfgfWZ+U/NjyRJ2p16jriPBz4GnBwRfbWvDzY5lyRpF8Yc487MR4GYgCySpDp456QkFcbilqTCWNySVBiLW5IKY3FLUmEsbkkqjMUtSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1JhLG5JKozFLUmFsbglqTAWtyQVxuKWpMJY3JJUGItbkgpjcUtSYcYs7oj4akRsioi1ExFIkrR79Rxxfw14f5NzSJLqNGZxZ+YKYPMEZJEk1WFqVSuKiCXAEoCurq6qVqtJrL/jvFZHULMtPaBpq+7vaNqq215lJyczc1lm9mZmb2dnZ1WrlSTtxKtKJKkwFrckFaaeywG/BXwfODwiBiLiz5sfS5K0K2OenMzMcyciiCSpPg6VSFJhLG5JKozFLUmFsbglqTAWtyQVxuKWpMJY3JJUGItbkgpjcUtSYSxuSSqMxS1JhbG4JakwFrckFcbilqTCWNySVBiLW5IKY3FLUmEsbkkqjMUtSYWxuCWpMHUVd0S8PyKejoiNEXFls0NJknZtzOKOiCnAjcAHgKOAcyPiqGYHkySNrp4j7oXAxsx8NjN/C9wGnN7cWJKkXamnuGcBz4+YH6g9JklqgalVrSgilgBLarOvRMTToyw2E3ip7nVWEax+v8927QRvuWY3W92j/TbBzDY+Zttz7ZoLtmdrrDsOqXfBeor7BeDtI+Zn1x57ncxcBizb3YoiYmVm9tYbbiKZbXzMNj5m23PtmgsmPls9QyVPAodFRE9E7A2cA/x7c2NJknZlzCPuzByKiL8EvgtMAb6ameuankySNKq6xrgz89vAtyvY3m6HUlrMbONjtvEx255r11wwwdkiMydye5KkBnnLuyQVppLiHuuW+Ii4LCJ+FBF9EfHoyDsvI+Kq2uuejog/qSJPFdkiYkZEPBQRr0TEl6vO1WC2UyJiVe25VRFxchtlW1h7rC8ifhgRZ7ZLthHPd9W+r59ul2wR0R0Rvxmx7/6lXbLVnjsmIr4fEetqy3S0Q7aIOH/EPuuLiNciYn6bZJsWEbfUnlsfEVdVFiozG/pi+ITlM8ChwN7AD4Gjdlpm/xHTpwHfqU0fVVt+H6Cntp4pjWaqKNt04ATgMuDLVWWqKNsC4G216aOBF9oo277A1Nr0wcCm7fOtzjbisTuBO4BPt9F+6wbWVv33rKJsU4E1wDtq8zPa5d/pTsvMA55po/12HnBbbXpfoB/oriJXFUfcY94Sn5kvj5idDmwfWD+99sa2ZuZPgI219VVl3Nky89XMfBTYUmGeqrI9lZk/qz2+DnhTROzTJtl+nZlDtcc7+P33uuXZACLiDOAnDO+3qjWUrckayXYqsCYzf1hbbjAzt7VJtpHOrb22So1kS2B6REwF3gT8Fhi57LhVcefkaLfEv2vnhSLiL4C/Zvh/re0/2s8CfrDTa6u8nb6RbM1WVbaPAKszc2u7ZIuIdwFfZfhOsI+NKPKWZouINwNXAKcAlQ+TNJKtpicinmL4H/fVmflIm2SbA2REfBfoZPhg6wttkm2ks6n+c5QayXZnLc/PGT7i/lRmbq4i1ISdnMzMGzPzDxn+h3P1RG23HqVmi4i5wD8Cl7ZTtsx8PDPnAscBV1U9HtpAtqXAP2fmKxOdZ6RdZPs50JWZCxgugOURsX+bZJvK8LDh+bU/z4yIRW2SDdhxsPDrzFw70bl2k20hsA14G8NDwZdHxKFVbK+K4q7rlvgRbgPOGOdrJzJbszWULSJmA/cAF2bmM+2UbbvMXA+8wvA4fDtkexfwhYjoBz4J/F0M31zW8my14cLB2vQqhsdV57RDNoaPMldk5kuZ+WuG7+k4tk2ybXcO8K0KM23XSLbzGB7v/l1mbgIeA6q5Lb6CwfupwLMM/4+yffB+7k7LHDZi+sPAytr0XF5/cvJZqj3pMe5sIx67mOacnGxkv72ltvxZVeeqIFsPvz85eQjwM2BmO2TbaZmlVH9yspH91rn97z7DJ8JeAP6gTbIdCKymduIZeABY3A7ZavN71fbXoVV+PyvYb1cAN9empwM/Bo6pJFdFb+6DwH8xfJTwmdpjfw+cVpv+IsMng/qAh0a+ceAztdc9DXygCTu+kWz9wGaGjxoH2OlscquyMfyj2Ku1x7d/HdQm2T424vHVwBnt9D0dsY6lVFzcDe63j+y03z7cLtlqz11Qe24t8IU2y3YS8IOqM1XwPX0zw1cvrWO4tP+mqkzeOSlJhfHOSUkqjMUtSYWxuCWpMBa3JBXG4pakwljcklQYi1uSCmNxS1Jh/g81JqEtfthXyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5fc2e7518>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
