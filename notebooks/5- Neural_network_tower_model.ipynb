{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# Solve the estimation problem with neural network tower model on the supervised dataset from the Jeopardy-like logs\n",
    "# ===========================================================\n",
    "\n",
    "Goals:\n",
    "1. Split the data into test and train\n",
    "2. Formulate the neural network based model\n",
    "3. Compute train and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last update: 09 Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv1D, LSTM, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "from mytimer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = '/home/omid/Datasets/Jeopardy/supervised_data.pk'\n",
    "# data_fpath = '/home/omid/Datasets/Jeopardy/supervised_data_roberta.pk'\n",
    "test_fraction = 0.2\n",
    "runs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix_err(true_matrix: np.matrix, pred_matrix: np.matrix, type_str: str = 'frob_norm') -> float:\n",
    "    if type_str == 'frob_norm':\n",
    "        frob_norm_of_difference = np.linalg.norm(true_matrix - pred_matrix)\n",
    "        err = frob_norm_of_difference / np.linalg.norm(true_matrix)\n",
    "        return err\n",
    "    elif type_str == 'corr':\n",
    "#         (r, p) = sp.stats.spearmanr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        (r, p) = sp.stats.pearsonr(np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        if p > 0.05:\n",
    "            r = 0\n",
    "        return r\n",
    "    elif type_str == 'cosine':\n",
    "        err = sp.spatial.distance.cosine(\n",
    "            np.array(true_matrix.flatten())[0], np.array(pred_matrix.flatten())[0])\n",
    "        return err\n",
    "    else:\n",
    "        raise ValueError('Wrong type_str was given.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eigvec_of_laplacian(A: np.matrix) -> np.matrix:\n",
    "#     D = np.diag(np.array(np.sum(A, axis=0))[0])\n",
    "#     L = D - A\n",
    "#     return np.matrix(np.linalg.eig(L)[1])\n",
    "    n, m = A.shape\n",
    "    diags = A.sum(axis=1).flatten()\n",
    "    D = sp.sparse.spdiags(diags, [0], m, n, format='csr')\n",
    "    L = D - A\n",
    "    with sp.errstate(divide='ignore'):\n",
    "        diags_sqrt = 1.0/sp.sqrt(diags)\n",
    "    diags_sqrt[sp.isinf(diags_sqrt)] = 0\n",
    "    DH = sp.sparse.spdiags(diags_sqrt, [0], m, n, format='csr')\n",
    "    DH = DH.todense()\n",
    "    normalized_L = DH.dot(L.dot(DH))\n",
    "    return normalized_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape, dtype=None):\n",
    "    return np.ones(shape) * 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_it(data_fpath)\n",
    "print(len(data['X']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = []\n",
    "for i in range(len(data['y'])):\n",
    "    mats.append(data['y'][i]['influence_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25906952, 0.24905243, 0.25700584, 0.23487221],\n",
       "       [0.22331056, 0.32544628, 0.22024244, 0.23100072],\n",
       "       [0.21267519, 0.25090613, 0.31034735, 0.22607133],\n",
       "       [0.25209233, 0.23995288, 0.2409886 , 0.26696619]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12121653, 0.08048964, 0.09161217, 0.07770627],\n",
       "       [0.09630495, 0.17456327, 0.08476215, 0.10845003],\n",
       "       [0.09183082, 0.12230915, 0.17582025, 0.09195666],\n",
       "       [0.09730267, 0.06870681, 0.06307793, 0.09241992]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mats, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulating the tower model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only content embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7396 - accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7387 - accuracy: 0.0188\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 0.7385 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7382 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7379 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7377 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7372 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7373 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7364 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7367 - accuracy: 0.0188\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7388 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7379 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7375 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7372 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7366 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7361 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7363 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7359 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7353 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7355 - accuracy: 0.0163\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7384 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7376 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7376 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 98us/sample - loss: 0.7368 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7369 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7366 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7369 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7360 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7364 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7363 - accuracy: 0.0181\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7395 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 124us/sample - loss: 0.7383 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 103us/sample - loss: 0.7384 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7384 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7380 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7379 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7375 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7371 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7371 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7362 - accuracy: 0.0177\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7395 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 101us/sample - loss: 0.7391 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.7385 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7387 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7383 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7376 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7373 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7373 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7370 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7373 - accuracy: 0.0165\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7386 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 0.7383 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7377 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7370 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7373 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7363 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7366 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7361 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7360 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7354 - accuracy: 0.0181\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7392 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7384 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7384 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7378 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7375 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7371 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7364 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7365 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7357 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7356 - accuracy: 0.0191\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7405 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 112us/sample - loss: 0.7396 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 103us/sample - loss: 0.7392 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7386 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7381 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7387 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7378 - accuracy: 0.0179\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7372 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7368 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7370 - accuracy: 0.0179\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7389 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 0.7381 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7379 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7373 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7372 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7369 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7365 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7362 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7360 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7354 - accuracy: 0.0167\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7391 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 109us/sample - loss: 0.7384 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 113us/sample - loss: 0.7381 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7372 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7376 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7370 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7371 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7370 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7367 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7363 - accuracy: 0.0191\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7385 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 120us/sample - loss: 0.7380 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7376 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7375 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7373 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7364 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7369 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7361 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7366 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7358 - accuracy: 0.0179\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7383 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7372 - accuracy: 0.0195\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7372 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7372 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7366 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7361 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7360 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7358 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7355 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7353 - accuracy: 0.0195\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7399 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7389 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7386 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7381 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7381 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7376 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7368 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7371 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7369 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7370 - accuracy: 0.0156\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7393 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7387 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7379 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7373 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7372 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7374 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7369 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7364 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7366 - accuracy: 0.0186\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7391 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7384 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7382 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7377 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7378 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7371 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7366 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7364 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7362 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7357 - accuracy: 0.0163\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7381 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 108us/sample - loss: 0.7379 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 107us/sample - loss: 0.7376 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7369 - accuracy: 0.0193\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 96us/sample - loss: 0.7365 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7362 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7358 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7358 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7356 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7361 - accuracy: 0.0193\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7391 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7385 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7384 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7377 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7383 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7377 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7368 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7368 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7365 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7364 - accuracy: 0.0167\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7389 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7381 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7377 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7377 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7374 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7372 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7373 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 0.7366 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7360 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7358 - accuracy: 0.0177\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7385 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7383 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7383 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7380 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7379 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7378 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7371 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7371 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7368 - accuracy: 0.0170\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7389 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7380 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7379 - accuracy: 0.0191\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7374 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7374 - accuracy: 0.0191\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7373 - accuracy: 0.0191\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 0.7368 - accuracy: 0.0191\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7366 - accuracy: 0.0191\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 0.7363 - accuracy: 0.0191\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7357 - accuracy: 0.0191\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7387 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7382 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7376 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7376 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7373 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7368 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7366 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7367 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 0.7366 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7362 - accuracy: 0.0193\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7387 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7379 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7378 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 89us/sample - loss: 0.7378 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 0.7374 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7374 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7371 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 0.7368 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7365 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7367 - accuracy: 0.0165\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7393 - accuracy: 0.0151\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 85us/sample - loss: 0.7386 - accuracy: 0.0151\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 0.7381 - accuracy: 0.0151\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7381 - accuracy: 0.0151\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7373 - accuracy: 0.0151\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7371 - accuracy: 0.0151\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7374 - accuracy: 0.0151\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 0.7368 - accuracy: 0.0151\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 0.7362 - accuracy: 0.0151\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 0.7364 - accuracy: 0.0151\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7383 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 105us/sample - loss: 0.7378 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 100us/sample - loss: 0.7376 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7377 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 0.7370 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 0.7371 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7368 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7364 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7363 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7361 - accuracy: 0.0156\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7394 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7384 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7382 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7382 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7376 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7377 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7382 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7369 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7371 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 0.7363 - accuracy: 0.0156\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7396 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 99us/sample - loss: 0.7396 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7393 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 0.7389 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 104us/sample - loss: 0.7380 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 0.7381 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 0.7375 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7375 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7368 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7372 - accuracy: 0.0186\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7401 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 0.7393 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7388 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7387 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7387 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7382 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 0.7386 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7381 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 0.7373 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7371 - accuracy: 0.0177\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 2ms/sample - loss: 0.7380 - accuracy: 0.0160\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7375 - accuracy: 0.0160\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7374 - accuracy: 0.0160\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 0.7372 - accuracy: 0.0160\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7365 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 0.7361 - accuracy: 0.0160\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 0.7360 - accuracy: 0.0160\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7358 - accuracy: 0.0160\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 0.7356 - accuracy: 0.0160\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7355 - accuracy: 0.0160\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7390 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 0.7385 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 97us/sample - loss: 0.7381 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 0.7381 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7377 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7375 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7372 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7371 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 0.7367 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 0.7367 - accuracy: 0.0172\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 0s 2ms/sample - loss: 0.7400 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 106us/sample - loss: 0.7395 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 0.7390 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 0.7386 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 0.7386 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 78us/sample - loss: 0.7385 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7382 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 0.7382 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 0.7379 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 0.7377 - accuracy: 0.0163\n",
      "It took 30.30 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "        \n",
    "#         mats = []\n",
    "#         for i in range(len(y_train)):\n",
    "#             mats.append(y_train[i]['influence_matrix'])\n",
    "#         average_matrix = np.mean(mats, axis=0)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']            \n",
    "#             flatten_X_train.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_train.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_train.append(np.array(label.flatten())[0])\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "#             flatten_X_test.append(np.array(features['reply_duration'].flatten())[0])\n",
    "            flatten_X_test.append(features['content_embedding_matrix'].flatten())\n",
    "            flatten_y_test.append(np.array(label.flatten())[0])\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu', input_shape=(3072,)),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "#             Dense(16, kernel_initializer='he_normal', activation='softmax')])\n",
    "            Dense(16, kernel_initializer=my_init, activation='softmax')])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "#         model = Sequential([\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 input_shape=(3072,),\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=64,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=16,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='softmax',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1))\n",
    "#         ])\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix']\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6358637687891749 +- 0.017407726721425588\n",
      "uniform: 0.3522141490130312 +- 0.018461737356623154\n",
      "model: 0.34663943089383537 +- 0.016315834977931095\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc43614d0f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = True\n",
    "one_type_network = 'reply_duration'   # 'emotion_dominance'\n",
    "input_dim = 80\n",
    "lambda1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1129.2028 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 110us/sample - loss: 1064.8313 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1003.3088 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 944.0386 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 888.0018 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 834.2492 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 782.8130 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 733.7862 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 686.8196 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 642.0795 - accuracy: 0.0181\n",
      "Run 1 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1139.9742 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1075.5409 - accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1014.2850 - accuracy: 0.0158\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 954.9360 - accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 898.0919 - accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 843.4122 - accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 791.3481 - accuracy: 0.0158\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 741.4664 - accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 693.7342 - accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 648.2541 - accuracy: 0.0158\n",
      "Run 2 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1155.9748 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 1090.9233 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1029.0111 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 968.2999 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 910.9342 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 856.2688 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 803.3710 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 752.9869 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 704.5878 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 658.8891 - accuracy: 0.0167\n",
      "Run 3 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1166.2186 - accuracy: 0.0191\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1100.8335 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1039.0170 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 979.6093 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 922.9814 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 869.0565 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 816.9134 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 767.2183 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 719.6365 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 674.2045 - accuracy: 0.0193\n",
      "Run 4 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1144.1854 - accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 1079.3233 - accuracy: 0.0156\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1017.7338 - accuracy: 0.0156\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 958.4422 - accuracy: 0.0156\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 901.5538 - accuracy: 0.0156\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 847.4018 - accuracy: 0.0156\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 795.4554 - accuracy: 0.0156\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 745.5239 - accuracy: 0.0156\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 698.0062 - accuracy: 0.0156\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 652.8114 - accuracy: 0.0156\n",
      "Run 5 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1156.1080 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 1090.5628 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 1028.1691 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 968.5407 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 911.9006 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 857.6487 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 805.6659 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 756.2174 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 708.9602 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 663.9904 - accuracy: 0.0167\n",
      "Run 6 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1143.5085 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 1078.5653 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1016.2720 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 957.1737 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 900.0817 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 845.5307 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 793.4327 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 743.6954 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 696.2274 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 651.1582 - accuracy: 0.0167\n",
      "Run 7 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1159.9867 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1096.0405 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1033.7801 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 974.1174 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 916.7466 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 862.4249 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 810.4289 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 760.2302 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 712.5842 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 667.2200 - accuracy: 0.0177\n",
      "Run 8 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1177.5967 - accuracy: 0.0165\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 93us/sample - loss: 1112.2172 - accuracy: 0.0165\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 91us/sample - loss: 1049.9725 - accuracy: 0.0165\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 989.7653 - accuracy: 0.0165\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 931.7611 - accuracy: 0.0165\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 876.5170 - accuracy: 0.0165\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 823.5754 - accuracy: 0.0165\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 772.8690 - accuracy: 0.0165\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 724.5442 - accuracy: 0.0165\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 678.4924 - accuracy: 0.0165\n",
      "Run 9 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1173.5135 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 1108.9259 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1046.7414 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 987.3347 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 929.5036 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 874.5877 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 821.9335 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 771.0937 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 722.9175 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 676.6407 - accuracy: 0.0179\n",
      "Run 10 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1148.4148 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1083.7283 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 1021.9998 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 963.2463 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 907.0173 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 852.7526 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 801.2573 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 751.7239 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 704.4360 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 659.2564 - accuracy: 0.0177\n",
      "Run 11 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1166.1102 - accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 1100.7097 - accuracy: 0.0188\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1037.8269 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 977.7264 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 920.4520 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 865.4415 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 813.2466 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 763.0242 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 715.1081 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 669.3643 - accuracy: 0.0188\n",
      "Run 12 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1140.4614 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1074.4964 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1013.3498 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 953.7008 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 896.8580 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 842.7106 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 790.7675 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 741.4915 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 694.4414 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 649.8993 - accuracy: 0.0177\n",
      "Run 13 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1171.5424 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1107.0800 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1045.5637 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 986.0753 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 928.6300 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 873.6497 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 821.0766 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 770.7407 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 722.5543 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 676.6280 - accuracy: 0.0193\n",
      "Run 14 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1146.3331 - accuracy: 0.0153\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 1081.2212 - accuracy: 0.0153\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 1019.7446 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 960.3851 - accuracy: 0.0153\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 903.4525 - accuracy: 0.0153\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 848.9426 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 796.4592 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 746.7560 - accuracy: 0.0153\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 699.3042 - accuracy: 0.0153\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 654.3406 - accuracy: 0.0153\n",
      "Run 15 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1s 3ms/sample - loss: 1135.1535 - accuracy: 0.0181\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 95us/sample - loss: 1071.0275 - accuracy: 0.0181\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 1008.8973 - accuracy: 0.0181\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 949.9622 - accuracy: 0.0181\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 892.7380 - accuracy: 0.0181\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 838.4916 - accuracy: 0.0181\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 786.4447 - accuracy: 0.0181\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 736.9422 - accuracy: 0.0181\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 689.7770 - accuracy: 0.0181\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 644.7653 - accuracy: 0.0181\n",
      "Run 16 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1161.7091 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1095.6503 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1033.5331 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 973.4751 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 916.1235 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 861.1882 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 809.0379 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 759.1021 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 711.4668 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 665.8519 - accuracy: 0.0167\n",
      "Run 17 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.4299 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 1083.3459 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 1021.4114 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 962.3643 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 905.9802 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 852.0611 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 800.2745 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 751.0585 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 704.2451 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 659.3552 - accuracy: 0.0177\n",
      "Run 18 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1156.1761 - accuracy: 0.0153\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 1091.2596 - accuracy: 0.0153\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1028.8294 - accuracy: 0.0153\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 69us/sample - loss: 968.9954 - accuracy: 0.0153\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 911.8857 - accuracy: 0.0153\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 857.2292 - accuracy: 0.0153\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 805.2266 - accuracy: 0.0153\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 755.4080 - accuracy: 0.0153\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 707.9492 - accuracy: 0.0153\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 662.5152 - accuracy: 0.0153\n",
      "Run 19 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1148.6885 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 1083.5594 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 1021.5588 - accuracy: 0.0195\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 962.2911 - accuracy: 0.0195\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 905.5994 - accuracy: 0.0195\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 851.2257 - accuracy: 0.0195\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 799.3261 - accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 749.3376 - accuracy: 0.0195\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 701.6837 - accuracy: 0.0195\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 656.0672 - accuracy: 0.0195\n",
      "Run 20 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1171.1398 - accuracy: 0.0195\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1104.9599 - accuracy: 0.0193\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1041.6840 - accuracy: 0.0197\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 981.1663 - accuracy: 0.0197\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 924.3704 - accuracy: 0.0197\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 79us/sample - loss: 869.1978 - accuracy: 0.0197\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 816.4479 - accuracy: 0.0197\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 766.0721 - accuracy: 0.0197\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 717.7793 - accuracy: 0.0197\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 672.2426 - accuracy: 0.0197\n",
      "Run 21 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.1805 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1083.1277 - accuracy: 0.0179\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 90us/sample - loss: 1021.2257 - accuracy: 0.0179\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 961.9440 - accuracy: 0.0179\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 905.2668 - accuracy: 0.0179\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 850.9572 - accuracy: 0.0179\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 57us/sample - loss: 798.9083 - accuracy: 0.0179\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 749.1899 - accuracy: 0.0179\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 54us/sample - loss: 701.9336 - accuracy: 0.0179\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 53us/sample - loss: 656.7258 - accuracy: 0.0179\n",
      "Run 22 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1132.1559 - accuracy: 0.0193\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1066.4077 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 84us/sample - loss: 1004.7243 - accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 82us/sample - loss: 945.1560 - accuracy: 0.0193\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 888.2962 - accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 833.9246 - accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 56us/sample - loss: 781.9596 - accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 732.5152 - accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 72us/sample - loss: 685.9425 - accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 641.3913 - accuracy: 0.0193\n",
      "Run 23 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1159.1377 - accuracy: 0.0160\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 87us/sample - loss: 1093.9618 - accuracy: 0.0160\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 83us/sample - loss: 1031.2505 - accuracy: 0.0160\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 971.9063 - accuracy: 0.0160\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 914.4294 - accuracy: 0.0160\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 859.8280 - accuracy: 0.0160\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 807.2810 - accuracy: 0.0160\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 756.9763 - accuracy: 0.0160\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 709.1444 - accuracy: 0.0160\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 663.4555 - accuracy: 0.0160\n",
      "Run 24 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1138.2437 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1072.4098 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 1010.2879 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 70us/sample - loss: 950.3695 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 893.7916 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 839.6181 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 787.5018 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 738.4247 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 61us/sample - loss: 691.2649 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 646.4815 - accuracy: 0.0167\n",
      "Run 25 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1153.9272 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1088.6069 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 1027.2105 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 967.5574 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 86us/sample - loss: 910.1670 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 855.7661 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 803.7105 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 65us/sample - loss: 753.9431 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 706.4912 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 60us/sample - loss: 661.3029 - accuracy: 0.0167\n",
      "Run 26 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 4ms/sample - loss: 1154.9127 - accuracy: 0.0184\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1089.9382 - accuracy: 0.0186\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 1027.5484 - accuracy: 0.0186\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 88us/sample - loss: 967.5648 - accuracy: 0.0186\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 909.7255 - accuracy: 0.0186\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 855.2228 - accuracy: 0.0186\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 802.2617 - accuracy: 0.0186\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 62us/sample - loss: 752.1714 - accuracy: 0.0186\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 704.3723 - accuracy: 0.0186\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 658.7658 - accuracy: 0.0186\n",
      "Run 27 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1157.7748 - accuracy: 0.0186\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 1091.6244 - accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 92us/sample - loss: 1028.9416 - accuracy: 0.0188\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 968.7104 - accuracy: 0.0188\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 911.3704 - accuracy: 0.0188\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 71us/sample - loss: 856.3421 - accuracy: 0.0188\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 77us/sample - loss: 803.3847 - accuracy: 0.0188\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 753.3710 - accuracy: 0.0188\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 63us/sample - loss: 705.7298 - accuracy: 0.0188\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 660.5937 - accuracy: 0.0188\n",
      "Run 28 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1148.1463 - accuracy: 0.0179\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 1083.3388 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 58us/sample - loss: 1021.8961 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 80us/sample - loss: 961.9822 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 905.4330 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 850.8270 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 59us/sample - loss: 798.6586 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 55us/sample - loss: 748.8168 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 66us/sample - loss: 701.3088 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 64us/sample - loss: 655.8904 - accuracy: 0.0177\n",
      "Run 29 ...\n",
      "Train on 269 samples\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 1s 3ms/sample - loss: 1147.6232 - accuracy: 0.0163\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 0s 96us/sample - loss: 1082.2249 - accuracy: 0.0163\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 0s 94us/sample - loss: 1020.0382 - accuracy: 0.0163\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 0s 81us/sample - loss: 960.7634 - accuracy: 0.0163\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 0s 75us/sample - loss: 903.7219 - accuracy: 0.0163\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 0s 76us/sample - loss: 849.2745 - accuracy: 0.0163\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 0s 74us/sample - loss: 797.2047 - accuracy: 0.0163\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 0s 68us/sample - loss: 747.3739 - accuracy: 0.0163\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 0s 67us/sample - loss: 699.9482 - accuracy: 0.0163\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 0s 73us/sample - loss: 654.8754 - accuracy: 0.0163\n",
      "It took 40.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0])\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(np.array(features[one_type_network].flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0])\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim,),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=64,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=32,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix']\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6310301214868926 +- 0.01399059267030896\n",
      "uniform: 0.34745737869634064 +- 0.017530337002096035\n",
      "model: 0.34513695020571783 +- 0.016975889090539077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc547f7feb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_networks = All\n",
    "one_type_network = 'reply_duration'   # 'emotion_dominance'\n",
    "input_dim = 16\n",
    "lambda1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2328.1521 - accuracy: 0.0137\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 2224.8803 - accuracy: 0.0137\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 2136.6592 - accuracy: 0.0137\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 2058.9072 - accuracy: 0.0137\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 1987.1194 - accuracy: 0.0137\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 1920.5766 - accuracy: 0.0137\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 1857.6044 - accuracy: 0.0137\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 1797.3332 - accuracy: 0.0137\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1739.3273 - accuracy: 0.0137\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 1683.2641 - accuracy: 0.0137\n",
      "Run 1 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2423.6701 - accuracy: 0.0162\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 79us/sample - loss: 2296.1992 - accuracy: 0.0162\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 2192.3648 - accuracy: 0.0162\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 2105.0188 - accuracy: 0.0162\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 2028.2467 - accuracy: 0.0162\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1958.6348 - accuracy: 0.0162\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1894.2799 - accuracy: 0.0162\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1833.5885 - accuracy: 0.0162\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1775.6212 - accuracy: 0.0162\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 63us/sample - loss: 1719.9062 - accuracy: 0.0162\n",
      "Run 2 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2293.9230 - accuracy: 0.0134\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 95us/sample - loss: 2187.1326 - accuracy: 0.0134\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 2094.8868 - accuracy: 0.0134\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 2014.7611 - accuracy: 0.0134\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1941.5324 - accuracy: 0.0134\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1874.2806 - accuracy: 0.0134\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 1810.7707 - accuracy: 0.0134\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1750.1939 - accuracy: 0.0134\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 1692.6378 - accuracy: 0.0134\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1637.2185 - accuracy: 0.0134\n",
      "Run 3 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2433.6544 - accuracy: 0.0162\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 2305.7652 - accuracy: 0.0162\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 2201.5930 - accuracy: 0.0162\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 2113.0864 - accuracy: 0.0162\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 2035.4788 - accuracy: 0.0162\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 1965.0320 - accuracy: 0.0162\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1899.9988 - accuracy: 0.0162\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 1838.6573 - accuracy: 0.0162\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1780.3902 - accuracy: 0.0162\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 55us/sample - loss: 1724.9561 - accuracy: 0.0162\n",
      "Run 4 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2466.1009 - accuracy: 0.0175\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 2331.3662 - accuracy: 0.0175\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 2220.0144 - accuracy: 0.0175\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 2125.9588 - accuracy: 0.0175\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 2043.9520 - accuracy: 0.0175\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1970.4122 - accuracy: 0.0175\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 1903.3207 - accuracy: 0.0175\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1840.7506 - accuracy: 0.0175\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1782.0368 - accuracy: 0.0175\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1725.9122 - accuracy: 0.0175\n",
      "Run 5 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2356.0901 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 2243.1525 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 90us/sample - loss: 2149.0323 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 2066.1524 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 1992.7516 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1924.6397 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 1861.2425 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 1801.1508 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1743.7629 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 53us/sample - loss: 1688.3595 - accuracy: 0.0167\n",
      "Run 6 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 2s 6ms/sample - loss: 2304.1299 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 2195.8668 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 2103.0471 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 2022.1604 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 1949.1524 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1882.1021 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 1819.0320 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1758.9888 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1701.7351 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1646.6133 - accuracy: 0.0172\n",
      "Run 7 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2437.4579 - accuracy: 0.0154\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 2309.6075 - accuracy: 0.0154\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 2202.7433 - accuracy: 0.0154\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 2112.5059 - accuracy: 0.0154\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 2032.9142 - accuracy: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1961.0035 - accuracy: 0.0154\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 1894.9165 - accuracy: 0.0154\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 1833.2831 - accuracy: 0.0154\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1774.7719 - accuracy: 0.0154\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 1718.7325 - accuracy: 0.0154\n",
      "Run 8 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2450.9738 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 99us/sample - loss: 2326.1657 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 95us/sample - loss: 2222.3188 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 2133.2157 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 2054.1072 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 1982.4430 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1916.1663 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1853.7217 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1794.4892 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 1737.7112 - accuracy: 0.0170\n",
      "Run 9 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2389.5479 - accuracy: 0.0157\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 92us/sample - loss: 2267.3919 - accuracy: 0.0162\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 2167.4947 - accuracy: 0.0162\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 2082.1784 - accuracy: 0.0162\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 2006.9912 - accuracy: 0.0162\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 1939.2086 - accuracy: 0.0162\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 1876.0506 - accuracy: 0.0162\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1816.3517 - accuracy: 0.0162\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1759.4338 - accuracy: 0.0162\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 1704.4325 - accuracy: 0.0162\n",
      "Run 10 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2309.2230 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 100us/sample - loss: 2201.2954 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 2109.8902 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 2029.3178 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 1955.9039 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1888.2038 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 1824.8725 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1765.1215 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 60us/sample - loss: 1707.7321 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1652.7880 - accuracy: 0.0170\n",
      "Run 11 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 2s 6ms/sample - loss: 2541.4155 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 2389.8599 - accuracy: 0.0175\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 2271.8629 - accuracy: 0.0175\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 2177.4322 - accuracy: 0.0175\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 2095.7299 - accuracy: 0.0175\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 2023.0433 - accuracy: 0.0175\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 1956.6627 - accuracy: 0.0175\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1894.7730 - accuracy: 0.0175\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1836.2357 - accuracy: 0.0175\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1780.2875 - accuracy: 0.0175\n",
      "Run 12 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2419.4515 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 2297.3819 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 2195.8378 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 2109.6742 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 2033.8733 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 1964.2626 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1899.3771 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1838.1960 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1779.8493 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 1723.8502 - accuracy: 0.0170\n",
      "Run 13 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2527.0291 - accuracy: 0.0134\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 2382.0265 - accuracy: 0.0134\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 2268.1557 - accuracy: 0.0134\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 2173.8767 - accuracy: 0.0134\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 2092.0046 - accuracy: 0.0134\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 60us/sample - loss: 2019.4649 - accuracy: 0.0134\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1953.1993 - accuracy: 0.0134\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 60us/sample - loss: 1891.2302 - accuracy: 0.0134\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 54us/sample - loss: 1832.7318 - accuracy: 0.0134\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 55us/sample - loss: 1776.8395 - accuracy: 0.0134\n",
      "Run 14 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2392.7202 - accuracy: 0.0142\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 98us/sample - loss: 2282.7256 - accuracy: 0.0142\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 90us/sample - loss: 2189.0090 - accuracy: 0.0142\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 2107.3869 - accuracy: 0.0142\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 2032.9475 - accuracy: 0.0142\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1964.7075 - accuracy: 0.0142\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 1900.6731 - accuracy: 0.0142\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 1839.4848 - accuracy: 0.0142\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1781.1598 - accuracy: 0.0142\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1724.6459 - accuracy: 0.0142\n",
      "Run 15 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 1s 4ms/sample - loss: 2395.9479 - accuracy: 0.0159\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 2277.8744 - accuracy: 0.0159\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 2180.1931 - accuracy: 0.0159\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 2095.2252 - accuracy: 0.0159\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 2019.9586 - accuracy: 0.0159\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1951.9185 - accuracy: 0.0159\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1888.6318 - accuracy: 0.0159\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 56us/sample - loss: 1828.6732 - accuracy: 0.0159\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 55us/sample - loss: 1771.7502 - accuracy: 0.0159\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 52us/sample - loss: 1716.5840 - accuracy: 0.0159\n",
      "Run 16 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2362.1218 - accuracy: 0.0147\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 2250.0510 - accuracy: 0.0147\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 2154.3212 - accuracy: 0.0147\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 2070.5795 - accuracy: 0.0147\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 1995.7628 - accuracy: 0.0147\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 1926.7288 - accuracy: 0.0147\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1862.3316 - accuracy: 0.0147\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 55us/sample - loss: 1800.9223 - accuracy: 0.0147\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1742.4748 - accuracy: 0.0147\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1686.3354 - accuracy: 0.0147\n",
      "Run 17 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 2s 7ms/sample - loss: 2246.0047 - accuracy: 0.0149\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 98us/sample - loss: 2147.0652 - accuracy: 0.0149\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 2061.2036 - accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 97us/sample - loss: 1984.9113 - accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 93us/sample - loss: 1914.8018 - accuracy: 0.0149\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 1849.3844 - accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 1787.3989 - accuracy: 0.0149\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1727.9310 - accuracy: 0.0149\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 1670.6928 - accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 1615.0851 - accuracy: 0.0149\n",
      "Run 18 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2442.9262 - accuracy: 0.0157\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 96us/sample - loss: 2316.4890 - accuracy: 0.0157\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 96us/sample - loss: 2210.7735 - accuracy: 0.0157\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 2121.7215 - accuracy: 0.0157\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 2041.8525 - accuracy: 0.0157\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 1969.4817 - accuracy: 0.0157\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 79us/sample - loss: 1902.3336 - accuracy: 0.0157\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 1839.6499 - accuracy: 0.0157\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1780.2095 - accuracy: 0.0157\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 1723.6122 - accuracy: 0.0157\n",
      "Run 19 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2400.2235 - accuracy: 0.0154\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 95us/sample - loss: 2281.3072 - accuracy: 0.0154\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 2182.2643 - accuracy: 0.0154\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 2097.1358 - accuracy: 0.0154\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 2021.0100 - accuracy: 0.0154\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 1952.0770 - accuracy: 0.0154\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 1888.0284 - accuracy: 0.0154\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 63us/sample - loss: 1827.3611 - accuracy: 0.0154\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1769.3083 - accuracy: 0.0154\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1713.7479 - accuracy: 0.0154\n",
      "Run 20 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2379.0948 - accuracy: 0.0147\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 97us/sample - loss: 2262.6642 - accuracy: 0.0152\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 92us/sample - loss: 2163.4363 - accuracy: 0.0152\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 2077.3602 - accuracy: 0.0152\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 2000.0363 - accuracy: 0.0152\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 1929.5714 - accuracy: 0.0152\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 1863.4319 - accuracy: 0.0152\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1800.9742 - accuracy: 0.0152\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 1741.4864 - accuracy: 0.0152\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 1684.6323 - accuracy: 0.0152\n",
      "Run 21 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2446.9965 - accuracy: 0.0144\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 2318.0006 - accuracy: 0.0144\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 2210.1735 - accuracy: 0.0144\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 2119.7443 - accuracy: 0.0144\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 2040.5215 - accuracy: 0.0144\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1969.2487 - accuracy: 0.0144\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1903.5991 - accuracy: 0.0144\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 1841.7545 - accuracy: 0.0144\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 63us/sample - loss: 1783.2780 - accuracy: 0.0144\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1727.1303 - accuracy: 0.0144\n",
      "Run 22 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2453.2018 - accuracy: 0.0154\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 2328.6566 - accuracy: 0.0157\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 2225.2381 - accuracy: 0.0157\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 63us/sample - loss: 2136.6784 - accuracy: 0.0157\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 2059.0048 - accuracy: 0.0157\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1988.3504 - accuracy: 0.0157\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1923.4485 - accuracy: 0.0157\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1861.7272 - accuracy: 0.0157\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 63us/sample - loss: 1803.1476 - accuracy: 0.0157\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 56us/sample - loss: 1746.8572 - accuracy: 0.0157\n",
      "Run 23 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 2s 7ms/sample - loss: 2291.9012 - accuracy: 0.0157\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 96us/sample - loss: 2189.5329 - accuracy: 0.0157\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 2101.0574 - accuracy: 0.0157\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 2022.0907 - accuracy: 0.0157\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 1949.9821 - accuracy: 0.0157\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1882.8375 - accuracy: 0.0157\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 1819.8478 - accuracy: 0.0157\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 1759.7417 - accuracy: 0.0157\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1702.4190 - accuracy: 0.0157\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 56us/sample - loss: 1647.5083 - accuracy: 0.0157\n",
      "Run 24 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2374.0988 - accuracy: 0.0154\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 2254.3409 - accuracy: 0.0154\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 2156.4928 - accuracy: 0.0154\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 2072.7518 - accuracy: 0.0154\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1997.9240 - accuracy: 0.0154\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 1929.3431 - accuracy: 0.0154\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 60us/sample - loss: 1865.8134 - accuracy: 0.0154\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1805.6982 - accuracy: 0.0154\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 56us/sample - loss: 1748.2751 - accuracy: 0.0154\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 57us/sample - loss: 1693.3265 - accuracy: 0.0154\n",
      "Run 25 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2297.7842 - accuracy: 0.0154\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 2192.4109 - accuracy: 0.0154\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 2102.5349 - accuracy: 0.0154\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 2023.7995 - accuracy: 0.0154\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 1952.4708 - accuracy: 0.0154\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 1886.1265 - accuracy: 0.0154\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 1823.6868 - accuracy: 0.0154\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 1764.1349 - accuracy: 0.0154\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 1707.1016 - accuracy: 0.0154\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 89us/sample - loss: 1651.7978 - accuracy: 0.0154\n",
      "Run 26 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2295.1832 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 2191.2529 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 2102.5035 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 2024.2867 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 1953.2567 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 58us/sample - loss: 1887.2843 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1824.6853 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 1764.7257 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 1707.3088 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1651.9324 - accuracy: 0.0170\n",
      "Run 27 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 4ms/sample - loss: 2332.5685 - accuracy: 0.0182\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 2221.3317 - accuracy: 0.0182\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 2127.3549 - accuracy: 0.0182\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 2046.9530 - accuracy: 0.0182\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 1974.3991 - accuracy: 0.0182\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1907.4599 - accuracy: 0.0182\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1844.6163 - accuracy: 0.0182\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 60us/sample - loss: 1784.6319 - accuracy: 0.0182\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 57us/sample - loss: 1727.4686 - accuracy: 0.0182\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 54us/sample - loss: 1672.1400 - accuracy: 0.0182\n",
      "Run 28 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2359.7646 - accuracy: 0.0149\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 2244.5181 - accuracy: 0.0149\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 2148.5248 - accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 79us/sample - loss: 2064.5545 - accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 1990.3476 - accuracy: 0.0149\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 1921.7414 - accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 1857.9134 - accuracy: 0.0149\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 1797.2707 - accuracy: 0.0149\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 57us/sample - loss: 1739.4352 - accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 56us/sample - loss: 1683.7238 - accuracy: 0.0149\n",
      "Run 29 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 2386.0844 - accuracy: 0.0142\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 2271.6985 - accuracy: 0.0142\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 95us/sample - loss: 2175.4981 - accuracy: 0.0142\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 2091.4534 - accuracy: 0.0142\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 2016.2122 - accuracy: 0.0142\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 1946.5901 - accuracy: 0.0142\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 1881.8912 - accuracy: 0.0142\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 61us/sample - loss: 1820.3680 - accuracy: 0.0142\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 59us/sample - loss: 1761.6880 - accuracy: 0.0142\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 57us/sample - loss: 1705.2983 - accuracy: 0.0142\n",
      "It took 51.66 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_train.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_train.append(\n",
    "                    np.array(get_eigvec_of_laplacian(features[one_type_network]).flatten())[0])\n",
    "            flatten_y_train.append(np.array(label.flatten())[0])\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            if all_networks:\n",
    "                flatten_X_test.append(np.hstack(\n",
    "                    [np.array(features['reply_duration'].flatten())[0],\n",
    "                     np.array(features['sentiment'].flatten())[0],\n",
    "                     np.array(features['emotion_arousal'].flatten())[0],\n",
    "                     np.array(features['emotion_dominance'].flatten())[0],\n",
    "                     np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            else:\n",
    "                flatten_X_test.append(\n",
    "                    np.array(get_eigvec_of_laplacian(features[one_type_network]).flatten())[0])\n",
    "            flatten_y_test.append(np.array(label.flatten())[0])\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim, 1),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            GlobalAveragePooling1D(),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(\n",
    "            np.reshape(flatten_X_train, (len(flatten_X_train), input_dim, 1)),\n",
    "            flatten_y_train,\n",
    "            epochs=10,\n",
    "            batch_size=64)\n",
    "        predicted = model.predict(np.reshape(flatten_X_test, (len(flatten_X_test), input_dim, 1)))\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix']\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6260289081160294 +- 0.019073459226181894\n",
      "uniform: 0.33818010164865875 +- 0.020875331206619\n",
      "model: 0.3375603516034832 +- 0.021005153522982288\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d35b7dd30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/omid/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7408 - accuracy: 0.0154\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 139us/sample - loss: 0.7402 - accuracy: 0.0154\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 104us/sample - loss: 0.7396 - accuracy: 0.0154\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 99us/sample - loss: 0.7396 - accuracy: 0.0154\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 101us/sample - loss: 0.7390 - accuracy: 0.0154\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 0.7390 - accuracy: 0.0154\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7389 - accuracy: 0.0154\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 0.7385 - accuracy: 0.0154\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7377 - accuracy: 0.0154\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 0.7381 - accuracy: 0.0154\n",
      "Run 1 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7406 - accuracy: 0.0159\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 103us/sample - loss: 0.7401 - accuracy: 0.0159\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7399 - accuracy: 0.0159\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7399 - accuracy: 0.0159\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7390 - accuracy: 0.0159\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7388 - accuracy: 0.0159\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 97us/sample - loss: 0.7389 - accuracy: 0.0159\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7389 - accuracy: 0.0159\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7390 - accuracy: 0.0159\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7384 - accuracy: 0.0159\n",
      "Run 2 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7406 - accuracy: 0.0152\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 117us/sample - loss: 0.7402 - accuracy: 0.0152\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7400 - accuracy: 0.0152\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 95us/sample - loss: 0.7401 - accuracy: 0.0152\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7396 - accuracy: 0.0152\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7390 - accuracy: 0.0152\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 0.7393 - accuracy: 0.0152\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7387 - accuracy: 0.0152\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 0.7389 - accuracy: 0.0152\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7385 - accuracy: 0.0152\n",
      "Run 3 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7407 - accuracy: 0.0147\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7404 - accuracy: 0.0147\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7400 - accuracy: 0.0147\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 92us/sample - loss: 0.7394 - accuracy: 0.0147\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7391 - accuracy: 0.0147\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 79us/sample - loss: 0.7389 - accuracy: 0.0147\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 90us/sample - loss: 0.7387 - accuracy: 0.0147\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7385 - accuracy: 0.0147\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7381 - accuracy: 0.0147\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7379 - accuracy: 0.0147\n",
      "Run 4 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7410 - accuracy: 0.0159\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 102us/sample - loss: 0.7401 - accuracy: 0.0159\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 0.7398 - accuracy: 0.0159\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 0.7394 - accuracy: 0.0159\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 92us/sample - loss: 0.7393 - accuracy: 0.0159\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7395 - accuracy: 0.0159\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7389 - accuracy: 0.0159\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7386 - accuracy: 0.0159\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7388 - accuracy: 0.0159\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 79us/sample - loss: 0.7387 - accuracy: 0.0159\n",
      "Run 5 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7410 - accuracy: 0.0167\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7401 - accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7396 - accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7396 - accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7396 - accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 0.7396 - accuracy: 0.0167\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7390 - accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7384 - accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7391 - accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 0.7385 - accuracy: 0.0167\n",
      "Run 6 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7407 - accuracy: 0.0142\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 104us/sample - loss: 0.7403 - accuracy: 0.0142\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 102us/sample - loss: 0.7401 - accuracy: 0.0142\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 97us/sample - loss: 0.7396 - accuracy: 0.0142\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7394 - accuracy: 0.0142\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7391 - accuracy: 0.0142\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7396 - accuracy: 0.0142\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7386 - accuracy: 0.0142\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7389 - accuracy: 0.0142\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7388 - accuracy: 0.0142\n",
      "Run 7 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7408 - accuracy: 0.0149\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 125us/sample - loss: 0.7396 - accuracy: 0.0149\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 96us/sample - loss: 0.7398 - accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 104us/sample - loss: 0.7393 - accuracy: 0.0149\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7396 - accuracy: 0.0149\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 99us/sample - loss: 0.7391 - accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 0.7389 - accuracy: 0.0149\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7384 - accuracy: 0.0149\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7384 - accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7382 - accuracy: 0.0149\n",
      "Run 8 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7409 - accuracy: 0.0142\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 93us/sample - loss: 0.7400 - accuracy: 0.0142\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 98us/sample - loss: 0.7397 - accuracy: 0.0142\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 0.7394 - accuracy: 0.0142\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 0.7396 - accuracy: 0.0142\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 0.7391 - accuracy: 0.0142\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7388 - accuracy: 0.0142\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7390 - accuracy: 0.0142\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7388 - accuracy: 0.0142\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7380 - accuracy: 0.0142\n",
      "Run 9 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7408 - accuracy: 0.0172\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 90us/sample - loss: 0.7402 - accuracy: 0.0172\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7396 - accuracy: 0.0172\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7395 - accuracy: 0.0172\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 90us/sample - loss: 0.7393 - accuracy: 0.0172\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7389 - accuracy: 0.0172\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7381 - accuracy: 0.0172\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7384 - accuracy: 0.0172\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7382 - accuracy: 0.0172\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7380 - accuracy: 0.0172\n",
      "Run 10 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7408 - accuracy: 0.0157\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7399 - accuracy: 0.0157\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7400 - accuracy: 0.0157\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7393 - accuracy: 0.0157\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7391 - accuracy: 0.0157\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7391 - accuracy: 0.0157\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7387 - accuracy: 0.0157\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7382 - accuracy: 0.0157\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 0.7384 - accuracy: 0.0157\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 0.7382 - accuracy: 0.0157\n",
      "Run 11 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7409 - accuracy: 0.0142\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 93us/sample - loss: 0.7402 - accuracy: 0.0142\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 95us/sample - loss: 0.7400 - accuracy: 0.0142\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 89us/sample - loss: 0.7397 - accuracy: 0.0142\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7396 - accuracy: 0.0142\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 90us/sample - loss: 0.7393 - accuracy: 0.0142\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7394 - accuracy: 0.0142\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7387 - accuracy: 0.0142\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7388 - accuracy: 0.0142\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 0.7387 - accuracy: 0.0142\n",
      "Run 12 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 111us/sample - loss: 0.7402 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7400 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7389 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7388 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 0.7385 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 62us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Run 13 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7407 - accuracy: 0.0149\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 103us/sample - loss: 0.7399 - accuracy: 0.0149\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 103us/sample - loss: 0.7396 - accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 102us/sample - loss: 0.7393 - accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7393 - accuracy: 0.0149\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7388 - accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 109us/sample - loss: 0.7389 - accuracy: 0.0149\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7386 - accuracy: 0.0149\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7388 - accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7383 - accuracy: 0.0149\n",
      "Run 14 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7409 - accuracy: 0.0157\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 107us/sample - loss: 0.7402 - accuracy: 0.0157\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 103us/sample - loss: 0.7399 - accuracy: 0.0157\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 105us/sample - loss: 0.7398 - accuracy: 0.0157\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7393 - accuracy: 0.0157\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7396 - accuracy: 0.0157\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7390 - accuracy: 0.0157\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 0.7389 - accuracy: 0.0157\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7389 - accuracy: 0.0157\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7386 - accuracy: 0.0157\n",
      "Run 15 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7406 - accuracy: 0.0182\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7401 - accuracy: 0.0182\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7398 - accuracy: 0.0182\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7392 - accuracy: 0.0182\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7393 - accuracy: 0.0182\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 0.7385 - accuracy: 0.0182\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7389 - accuracy: 0.0182\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7385 - accuracy: 0.0182\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7385 - accuracy: 0.0182\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7383 - accuracy: 0.0182\n",
      "Run 16 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7407 - accuracy: 0.0182\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 112us/sample - loss: 0.7399 - accuracy: 0.0182\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 100us/sample - loss: 0.7393 - accuracy: 0.0182\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 99us/sample - loss: 0.7390 - accuracy: 0.0182\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 96us/sample - loss: 0.7390 - accuracy: 0.0182\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 0.7384 - accuracy: 0.0182\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 0.7384 - accuracy: 0.0182\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7384 - accuracy: 0.0182\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7374 - accuracy: 0.0182\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 0.7379 - accuracy: 0.0182\n",
      "Run 17 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7408 - accuracy: 0.0175\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7399 - accuracy: 0.0175\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7397 - accuracy: 0.0175\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7397 - accuracy: 0.0175\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7390 - accuracy: 0.0175\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 0.7394 - accuracy: 0.0175\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7392 - accuracy: 0.0175\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 0.7386 - accuracy: 0.0175\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 0.7384 - accuracy: 0.0175\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 0.7386 - accuracy: 0.0175\n",
      "Run 18 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7407 - accuracy: 0.0132\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 100us/sample - loss: 0.7405 - accuracy: 0.0132\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 95us/sample - loss: 0.7394 - accuracy: 0.0132\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 92us/sample - loss: 0.7397 - accuracy: 0.0132\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7396 - accuracy: 0.0132\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7393 - accuracy: 0.0132\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7385 - accuracy: 0.0132\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7385 - accuracy: 0.0132\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7385 - accuracy: 0.0132\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7385 - accuracy: 0.0132\n",
      "Run 19 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7408 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 97us/sample - loss: 0.7401 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7401 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 89us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7392 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7383 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 80us/sample - loss: 0.7378 - accuracy: 0.0170\n",
      "Run 20 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7410 - accuracy: 0.0177\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 0.7407 - accuracy: 0.0177\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 0.7398 - accuracy: 0.0177\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7395 - accuracy: 0.0177\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7392 - accuracy: 0.0177\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 85us/sample - loss: 0.7399 - accuracy: 0.0177\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7389 - accuracy: 0.0177\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7391 - accuracy: 0.0177\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7384 - accuracy: 0.0177\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7385 - accuracy: 0.0177\n",
      "Run 21 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7410 - accuracy: 0.0152\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7408 - accuracy: 0.0152\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7402 - accuracy: 0.0152\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7398 - accuracy: 0.0152\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 0.7395 - accuracy: 0.0152\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 0.7398 - accuracy: 0.0152\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 70us/sample - loss: 0.7392 - accuracy: 0.0152\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 65us/sample - loss: 0.7391 - accuracy: 0.0152\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 0.7393 - accuracy: 0.0152\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 64us/sample - loss: 0.7386 - accuracy: 0.0152\n",
      "Run 22 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7411 - accuracy: 0.0149\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 102us/sample - loss: 0.7403 - accuracy: 0.0149\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7401 - accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 90us/sample - loss: 0.7401 - accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 0.7398 - accuracy: 0.0149\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7398 - accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 92us/sample - loss: 0.7398 - accuracy: 0.0149\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 75us/sample - loss: 0.7390 - accuracy: 0.0149\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7393 - accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 79us/sample - loss: 0.7391 - accuracy: 0.0149\n",
      "Run 23 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7404 - accuracy: 0.0159\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 103us/sample - loss: 0.7403 - accuracy: 0.0159\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 100us/sample - loss: 0.7395 - accuracy: 0.0159\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 92us/sample - loss: 0.7395 - accuracy: 0.0159\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7392 - accuracy: 0.0159\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7393 - accuracy: 0.0159\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7390 - accuracy: 0.0159\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7384 - accuracy: 0.0159\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7382 - accuracy: 0.0159\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 0.7380 - accuracy: 0.0159\n",
      "Run 24 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7408 - accuracy: 0.0164\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 107us/sample - loss: 0.7399 - accuracy: 0.0164\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 107us/sample - loss: 0.7398 - accuracy: 0.0164\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7399 - accuracy: 0.0164\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 0.7392 - accuracy: 0.0164\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7388 - accuracy: 0.0164\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 89us/sample - loss: 0.7382 - accuracy: 0.0164\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7386 - accuracy: 0.0164\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7379 - accuracy: 0.0164\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 76us/sample - loss: 0.7376 - accuracy: 0.0164\n",
      "Run 25 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 2ms/sample - loss: 0.7413 - accuracy: 0.0142\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7401 - accuracy: 0.0142\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7400 - accuracy: 0.0142\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 78us/sample - loss: 0.7395 - accuracy: 0.0142\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7395 - accuracy: 0.0142\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7391 - accuracy: 0.0142\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7390 - accuracy: 0.0142\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 0.7392 - accuracy: 0.0142\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 0.7383 - accuracy: 0.0142\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 67us/sample - loss: 0.7381 - accuracy: 0.0142\n",
      "Run 26 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 0.7411 - accuracy: 0.0159\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7400 - accuracy: 0.0159\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 82us/sample - loss: 0.7399 - accuracy: 0.0159\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 0.7393 - accuracy: 0.0159\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7392 - accuracy: 0.0159\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 84us/sample - loss: 0.7389 - accuracy: 0.0159\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7388 - accuracy: 0.0159\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 0.7386 - accuracy: 0.0159\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 69us/sample - loss: 0.7384 - accuracy: 0.0159\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7385 - accuracy: 0.0159\n",
      "Run 27 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7406 - accuracy: 0.0164\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 126us/sample - loss: 0.7401 - accuracy: 0.0164\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 113us/sample - loss: 0.7403 - accuracy: 0.0164\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 91us/sample - loss: 0.7396 - accuracy: 0.0164\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 94us/sample - loss: 0.7395 - accuracy: 0.0164\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7396 - accuracy: 0.0164\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 79us/sample - loss: 0.7392 - accuracy: 0.0164\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 71us/sample - loss: 0.7388 - accuracy: 0.0164\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 68us/sample - loss: 0.7382 - accuracy: 0.0164\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 66us/sample - loss: 0.7383 - accuracy: 0.0164\n",
      "Run 28 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7410 - accuracy: 0.0164\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 104us/sample - loss: 0.7401 - accuracy: 0.0164\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 113us/sample - loss: 0.7399 - accuracy: 0.0164\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 105us/sample - loss: 0.7393 - accuracy: 0.0164\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 88us/sample - loss: 0.7393 - accuracy: 0.0164\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 87us/sample - loss: 0.7392 - accuracy: 0.0164\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 73us/sample - loss: 0.7388 - accuracy: 0.0164\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7386 - accuracy: 0.0164\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 74us/sample - loss: 0.7387 - accuracy: 0.0164\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 72us/sample - loss: 0.7386 - accuracy: 0.0164\n",
      "Run 29 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/10\n",
      "247/247 [==============================] - 0s 2ms/sample - loss: 0.7407 - accuracy: 0.0170\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 0s 117us/sample - loss: 0.7406 - accuracy: 0.0170\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 0s 106us/sample - loss: 0.7401 - accuracy: 0.0170\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 0s 96us/sample - loss: 0.7401 - accuracy: 0.0170\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 0s 86us/sample - loss: 0.7397 - accuracy: 0.0170\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 0s 96us/sample - loss: 0.7396 - accuracy: 0.0170\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 0s 98us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 0s 83us/sample - loss: 0.7390 - accuracy: 0.0170\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 0s 81us/sample - loss: 0.7386 - accuracy: 0.0170\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 0s 77us/sample - loss: 0.7391 - accuracy: 0.0170\n",
      "It took 30.83 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']            \n",
    "            flatten_X_train.append(np.hstack(\n",
    "                [features['content_embedding_matrix'].flatten(),\n",
    "                 np.array(features['reply_duration'].flatten())[0],\n",
    "                 np.array(features['sentiment'].flatten())[0],\n",
    "                 np.array(features['emotion_arousal'].flatten())[0],\n",
    "                 np.array(features['emotion_dominance'].flatten())[0],\n",
    "                 np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            flatten_y_train.append(np.array(label.flatten())[0])\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            flatten_X_test.append(np.hstack(\n",
    "                [features['content_embedding_matrix'].flatten(),\n",
    "                 np.array(features['reply_duration'].flatten())[0],\n",
    "                 np.array(features['sentiment'].flatten())[0],\n",
    "                 np.array(features['emotion_arousal'].flatten())[0],\n",
    "                 np.array(features['emotion_dominance'].flatten())[0],\n",
    "                 np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            flatten_y_test.append(np.array(label.flatten())[0])\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu', input_shape=(3152,)),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, kernel_initializer='he_normal', activation='relu'),\n",
    "            Dropout(0.5),\n",
    "#             Dense(16, kernel_initializer='he_normal', activation='softmax')])\n",
    "            Dense(16, kernel_initializer=my_init, activation='softmax')])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "#         model = Sequential([\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 input_shape=(3072,),\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=64,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=32,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='relu',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1)),\n",
    "#             Dropout(0.5),\n",
    "#             Dense(\n",
    "#                 units=16,\n",
    "#                 kernel_initializer='he_normal',\n",
    "#                 activation='softmax',\n",
    "#                 kernel_regularizer=regularizers.l1(lambda1))\n",
    "#         ])\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "\n",
    "        model.fit(flatten_X_train, flatten_y_train, epochs=10, batch_size=32)\n",
    "\n",
    "        predicted = model.predict(flatten_X_test)\n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix']\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.629000514749951 +- 0.01566901726757875\n",
      "uniform: 0.3434295278358921 +- 0.02040265156790686\n",
      "model: 0.33717033132955276 +- 0.020186327022324663\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3da462e828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All with convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def my_metric(y_true, y_pred):\n",
    "#     return K.mean(y_pred)\n",
    "    return K.square(y_true - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 ...\n",
      "Train on 247 samples\n",
      "Epoch 1/200\n",
      "247/247 [==============================] - 2s 6ms/sample - loss: 112222.9294 - mae: 0.1970\n",
      "Epoch 2/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 89950.1876 - mae: 0.1916\n",
      "Epoch 3/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 74589.1161 - mae: 0.1905\n",
      "Epoch 4/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 63980.0150 - mae: 0.1901\n",
      "Epoch 5/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 56416.1194 - mae: 0.1901\n",
      "Epoch 6/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 50792.8900 - mae: 0.1900\n",
      "Epoch 7/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 46449.3858 - mae: 0.1900\n",
      "Epoch 8/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 43016.6834 - mae: 0.1900\n",
      "Epoch 9/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 40250.2278 - mae: 0.1901\n",
      "Epoch 10/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 37977.7197 - mae: 0.1900\n",
      "Epoch 11/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 36073.5552 - mae: 0.1900\n",
      "Epoch 12/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 34453.9292 - mae: 0.1900\n",
      "Epoch 13/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 33056.0108 - mae: 0.1900\n",
      "Epoch 14/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 31834.5979 - mae: 0.1900\n",
      "Epoch 15/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 30752.4795 - mae: 0.1900\n",
      "Epoch 16/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 29787.6852 - mae: 0.1900\n",
      "Epoch 17/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 28920.2794 - mae: 0.1900\n",
      "Epoch 18/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 28135.4679 - mae: 0.1900\n",
      "Epoch 19/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 27420.9289 - mae: 0.1900\n",
      "Epoch 20/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 26764.8571 - mae: 0.1900\n",
      "Epoch 21/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 26159.8282 - mae: 0.1900\n",
      "Epoch 22/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 25601.6435 - mae: 0.1900\n",
      "Epoch 23/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 25084.2476 - mae: 0.1900\n",
      "Epoch 24/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 24603.4115 - mae: 0.1900\n",
      "Epoch 25/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 24155.1105 - mae: 0.1900\n",
      "Epoch 26/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 23736.3091 - mae: 0.1900\n",
      "Epoch 27/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 23343.9334 - mae: 0.1900\n",
      "Epoch 28/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 22975.1874 - mae: 0.1900\n",
      "Epoch 29/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 22628.6298 - mae: 0.1900\n",
      "Epoch 30/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 22301.7343 - mae: 0.1900\n",
      "Epoch 31/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 21992.3127 - mae: 0.1900\n",
      "Epoch 32/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 21699.1545 - mae: 0.1900\n",
      "Epoch 33/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 21419.8012 - mae: 0.1900\n",
      "Epoch 34/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 21152.3457 - mae: 0.1900\n",
      "Epoch 35/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 20895.0622 - mae: 0.1900\n",
      "Epoch 36/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 20646.5263 - mae: 0.1899\n",
      "Epoch 37/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 20405.4372 - mae: 0.1899\n",
      "Epoch 38/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 20171.0223 - mae: 0.1899\n",
      "Epoch 39/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 19942.5186 - mae: 0.1899\n",
      "Epoch 40/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 19718.9210 - mae: 0.1899\n",
      "Epoch 41/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 19500.1466 - mae: 0.1899\n",
      "Epoch 42/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 19285.4645 - mae: 0.1899\n",
      "Epoch 43/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 19074.6826 - mae: 0.1899\n",
      "Epoch 44/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 18867.4274 - mae: 0.1899\n",
      "Epoch 45/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 18663.4835 - mae: 0.1899\n",
      "Epoch 46/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 18462.4358 - mae: 0.1899\n",
      "Epoch 47/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 18264.2054 - mae: 0.1899\n",
      "Epoch 48/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 18068.8193 - mae: 0.1899\n",
      "Epoch 49/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 17876.0040 - mae: 0.1899\n",
      "Epoch 50/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 17685.6163 - mae: 0.1899\n",
      "Epoch 51/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 17497.7572 - mae: 0.1899\n",
      "Epoch 52/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 17311.9793 - mae: 0.1899\n",
      "Epoch 53/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 17128.5903 - mae: 0.1899\n",
      "Epoch 54/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 16947.2398 - mae: 0.1899\n",
      "Epoch 55/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 16767.9152 - mae: 0.1899\n",
      "Epoch 56/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 16590.6972 - mae: 0.1899\n",
      "Epoch 57/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 16415.4716 - mae: 0.1899\n",
      "Epoch 58/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 16242.1948 - mae: 0.1899\n",
      "Epoch 59/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 16070.9168 - mae: 0.1899\n",
      "Epoch 60/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 15901.4049 - mae: 0.1899\n",
      "Epoch 61/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 15733.7911 - mae: 0.1899\n",
      "Epoch 62/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 15567.9834 - mae: 0.1899\n",
      "Epoch 63/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 15403.9465 - mae: 0.1899\n",
      "Epoch 64/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 15241.6433 - mae: 0.1899\n",
      "Epoch 65/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 15081.0235 - mae: 0.1899\n",
      "Epoch 66/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 14922.0621 - mae: 0.1899\n",
      "Epoch 67/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 14764.7366 - mae: 0.1899\n",
      "Epoch 68/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 14609.1317 - mae: 0.1899\n",
      "Epoch 69/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 14455.1410 - mae: 0.1899\n",
      "Epoch 70/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 14302.7672 - mae: 0.1899\n",
      "Epoch 71/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 14151.8954 - mae: 0.1899\n",
      "Epoch 72/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 14002.5746 - mae: 0.1899\n",
      "Epoch 73/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 13854.7667 - mae: 0.1899\n",
      "Epoch 74/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 13708.4728 - mae: 0.1899\n",
      "Epoch 75/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 13563.6856 - mae: 0.1899\n",
      "Epoch 76/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 13420.3810 - mae: 0.1899\n",
      "Epoch 77/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 13278.4699 - mae: 0.1899\n",
      "Epoch 78/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 13138.0746 - mae: 0.1899\n",
      "Epoch 79/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12999.0668 - mae: 0.1899\n",
      "Epoch 80/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12861.4229 - mae: 0.1899\n",
      "Epoch 81/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12725.2466 - mae: 0.1899\n",
      "Epoch 82/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12590.5211 - mae: 0.1899\n",
      "Epoch 83/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12457.1091 - mae: 0.1899\n",
      "Epoch 84/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12325.1352 - mae: 0.1899\n",
      "Epoch 85/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12194.4612 - mae: 0.1899\n",
      "Epoch 86/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 12065.1211 - mae: 0.1899\n",
      "Epoch 87/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11937.1974 - mae: 0.1899\n",
      "Epoch 88/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11810.4934 - mae: 0.1898\n",
      "Epoch 89/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11685.1704 - mae: 0.1898\n",
      "Epoch 90/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11561.0937 - mae: 0.1898\n",
      "Epoch 91/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11438.4407 - mae: 0.1898\n",
      "Epoch 92/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11316.8951 - mae: 0.1898\n",
      "Epoch 93/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11196.6121 - mae: 0.1898\n",
      "Epoch 94/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 11077.6370 - mae: 0.1898\n",
      "Epoch 95/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10959.9285 - mae: 0.1898\n",
      "Epoch 96/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10843.3204 - mae: 0.1898\n",
      "Epoch 97/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10728.1101 - mae: 0.1898\n",
      "Epoch 98/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10613.9651 - mae: 0.1898\n",
      "Epoch 99/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10500.8921 - mae: 0.1898\n",
      "Epoch 100/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10389.3158 - mae: 0.1898\n",
      "Epoch 101/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10278.5680 - mae: 0.1898\n",
      "Epoch 102/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10169.2368 - mae: 0.1898\n",
      "Epoch 103/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 10060.9652 - mae: 0.1898\n",
      "Epoch 104/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9953.8173 - mae: 0.1898\n",
      "Epoch 105/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9847.7704 - mae: 0.1898\n",
      "Epoch 106/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9742.8132 - mae: 0.1898\n",
      "Epoch 107/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9638.9298 - mae: 0.1898\n",
      "Epoch 108/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9536.3219 - mae: 0.1898\n",
      "Epoch 109/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9434.6069 - mae: 0.1898\n",
      "Epoch 110/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9334.0468 - mae: 0.1898\n",
      "Epoch 111/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9234.5664 - mae: 0.1898\n",
      "Epoch 112/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9136.1137 - mae: 0.1898\n",
      "Epoch 113/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 9038.6889 - mae: 0.1898\n",
      "Epoch 114/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8942.2525 - mae: 0.1898\n",
      "Epoch 115/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8846.8990 - mae: 0.1898\n",
      "Epoch 116/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8752.5341 - mae: 0.1898\n",
      "Epoch 117/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8659.2376 - mae: 0.1898\n",
      "Epoch 118/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8566.8769 - mae: 0.1898\n",
      "Epoch 119/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8475.4936 - mae: 0.1898\n",
      "Epoch 120/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8385.1754 - mae: 0.1898\n",
      "Epoch 121/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8295.7182 - mae: 0.1898\n",
      "Epoch 122/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8207.3031 - mae: 0.1898\n",
      "Epoch 123/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8119.9011 - mae: 0.1898\n",
      "Epoch 124/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 8033.3701 - mae: 0.1898\n",
      "Epoch 125/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7947.8162 - mae: 0.1898\n",
      "Epoch 126/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7863.1460 - mae: 0.1898\n",
      "Epoch 127/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7779.4400 - mae: 0.1898\n",
      "Epoch 128/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7696.6288 - mae: 0.1898\n",
      "Epoch 129/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7614.7314 - mae: 0.1898\n",
      "Epoch 130/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7533.7557 - mae: 0.1898\n",
      "Epoch 131/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7453.5994 - mae: 0.1898\n",
      "Epoch 132/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7374.3065 - mae: 0.1898\n",
      "Epoch 133/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7296.0076 - mae: 0.1898\n",
      "Epoch 134/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7218.3732 - mae: 0.1898\n",
      "Epoch 135/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7141.8495 - mae: 0.1898\n",
      "Epoch 136/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 7065.9916 - mae: 0.1898\n",
      "Epoch 137/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6990.9268 - mae: 0.1898\n",
      "Epoch 138/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6916.8061 - mae: 0.1898\n",
      "Epoch 139/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6843.4768 - mae: 0.1898\n",
      "Epoch 140/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6771.0012 - mae: 0.1898\n",
      "Epoch 141/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6699.2944 - mae: 0.1898\n",
      "Epoch 142/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6628.3941 - mae: 0.1898\n",
      "Epoch 143/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6558.2892 - mae: 0.1898\n",
      "Epoch 144/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6488.9654 - mae: 0.1898\n",
      "Epoch 145/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6420.4624 - mae: 0.1898\n",
      "Epoch 146/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6352.6456 - mae: 0.1898\n",
      "Epoch 147/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6285.6864 - mae: 0.1898\n",
      "Epoch 148/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6219.4184 - mae: 0.1898\n",
      "Epoch 149/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6153.9414 - mae: 0.1898\n",
      "Epoch 150/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6089.1662 - mae: 0.1898\n",
      "Epoch 151/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 6025.0736 - mae: 0.1898\n",
      "Epoch 152/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5961.8183 - mae: 0.1898\n",
      "Epoch 153/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5899.2828 - mae: 0.1898\n",
      "Epoch 154/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5837.4292 - mae: 0.1898\n",
      "Epoch 155/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5776.2491 - mae: 0.1898\n",
      "Epoch 156/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5715.8627 - mae: 0.1898\n",
      "Epoch 157/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5656.0805 - mae: 0.1898\n",
      "Epoch 158/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5597.0716 - mae: 0.1898\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 1s 3ms/sample - loss: 5538.6174 - mae: 0.1898\n",
      "Epoch 160/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5481.0124 - mae: 0.1898\n",
      "Epoch 161/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5423.9804 - mae: 0.1898\n",
      "Epoch 162/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5367.6413 - mae: 0.1898\n",
      "Epoch 163/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5311.8977 - mae: 0.1898\n",
      "Epoch 164/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5256.8088 - mae: 0.1898\n",
      "Epoch 165/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5202.4662 - mae: 0.1898\n",
      "Epoch 166/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5148.6377 - mae: 0.1898\n",
      "Epoch 167/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5095.5111 - mae: 0.1898\n",
      "Epoch 168/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 5042.9909 - mae: 0.1898\n",
      "Epoch 169/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4991.0780 - mae: 0.1898\n",
      "Epoch 170/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4939.8054 - mae: 0.1898\n",
      "Epoch 171/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4889.1390 - mae: 0.1898\n",
      "Epoch 172/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4839.0254 - mae: 0.1898\n",
      "Epoch 173/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4789.5205 - mae: 0.1898\n",
      "Epoch 174/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4740.6403 - mae: 0.1898\n",
      "Epoch 175/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4692.3039 - mae: 0.1898\n",
      "Epoch 176/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4644.5472 - mae: 0.1898\n",
      "Epoch 177/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4597.3689 - mae: 0.1898\n",
      "Epoch 178/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4550.8124 - mae: 0.1898\n",
      "Epoch 179/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4504.7266 - mae: 0.1898\n",
      "Epoch 180/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4459.2572 - mae: 0.1898\n",
      "Epoch 181/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4414.2901 - mae: 0.1898\n",
      "Epoch 182/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4369.8892 - mae: 0.1898\n",
      "Epoch 183/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4326.0415 - mae: 0.1898\n",
      "Epoch 184/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4282.6384 - mae: 0.1898\n",
      "Epoch 185/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4239.8160 - mae: 0.1898\n",
      "Epoch 186/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4197.5156 - mae: 0.1898\n",
      "Epoch 187/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4155.7204 - mae: 0.1898\n",
      "Epoch 188/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4114.4098 - mae: 0.1898\n",
      "Epoch 189/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4073.6057 - mae: 0.1898\n",
      "Epoch 190/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 4033.3056 - mae: 0.1898\n",
      "Epoch 191/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3993.5192 - mae: 0.1898\n",
      "Epoch 192/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3954.1572 - mae: 0.1898\n",
      "Epoch 193/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3915.2674 - mae: 0.1898\n",
      "Epoch 194/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3876.8847 - mae: 0.1898\n",
      "Epoch 195/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3838.9047 - mae: 0.1898\n",
      "Epoch 196/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3801.4281 - mae: 0.1898\n",
      "Epoch 197/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3764.3710 - mae: 0.1898\n",
      "Epoch 198/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3727.7954 - mae: 0.1898\n",
      "Epoch 199/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3691.6953 - mae: 0.1898\n",
      "Epoch 200/200\n",
      "247/247 [==============================] - 1s 3ms/sample - loss: 3655.9631 - mae: 0.1898\n",
      "It took 2.49 minutes.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    \n",
    "    input_dim = 3152\n",
    "\n",
    "    model_errs = []\n",
    "    random_errs = []\n",
    "    uniform_errs = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('Run', run, '...')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            data['X'], data['y'], test_size=test_fraction)\n",
    "\n",
    "        flatten_X_train = []\n",
    "        flatten_y_train = []\n",
    "        for i in range(len(X_train)):\n",
    "            features = X_train[i]\n",
    "            label = y_train[i]['influence_matrix']            \n",
    "            flatten_X_train.append(np.hstack(\n",
    "                [features['content_embedding_matrix'].flatten(),\n",
    "                 np.array(features['reply_duration'].flatten())[0],\n",
    "                 np.array(features['sentiment'].flatten())[0],\n",
    "                 np.array(features['emotion_arousal'].flatten())[0],\n",
    "                 np.array(features['emotion_dominance'].flatten())[0],\n",
    "                 np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            flatten_y_train.append(np.array(label.flatten())[0])\n",
    "        flatten_X_train = np.array(flatten_X_train)\n",
    "        flatten_y_train = np.array(flatten_y_train)\n",
    "\n",
    "        flatten_X_test = []\n",
    "        flatten_y_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = X_test[i]\n",
    "            label = y_test[i]['influence_matrix']\n",
    "            flatten_X_test.append(np.hstack(\n",
    "                [features['content_embedding_matrix'].flatten(),\n",
    "                 np.array(features['reply_duration'].flatten())[0],\n",
    "                 np.array(features['sentiment'].flatten())[0],\n",
    "                 np.array(features['emotion_arousal'].flatten())[0],\n",
    "                 np.array(features['emotion_dominance'].flatten())[0],\n",
    "                 np.array(features['emotion_valence'].flatten())[0]]))\n",
    "            flatten_y_test.append(np.array(label.flatten())[0])\n",
    "        flatten_X_test = np.array(flatten_X_test)\n",
    "        flatten_y_test = np.array(flatten_y_test)\n",
    "\n",
    "        \n",
    "    \n",
    "        model = Sequential([\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                input_shape=(input_dim, 1),\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                32,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            Conv1D(\n",
    "                64,\n",
    "                2,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='relu',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1)),\n",
    "            GlobalAveragePooling1D(),\n",
    "            Dropout(0.5),\n",
    "            Dense(\n",
    "                units=16,\n",
    "                kernel_initializer='he_normal',\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=regularizers.l1(lambda1),\n",
    "                activity_regularizer=regularizers.l1(lambda1))\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['mae'])\n",
    "        model.fit(\n",
    "            np.reshape(flatten_X_train, (len(flatten_X_train), input_dim, 1)),\n",
    "            flatten_y_train,\n",
    "            epochs=200,\n",
    "            batch_size=64)\n",
    "        predicted = model.predict(np.reshape(flatten_X_test, (len(flatten_X_test), input_dim, 1)))\n",
    "\n",
    "    \n",
    "\n",
    "        model_err = 0\n",
    "        uniform_err = 0\n",
    "        random_err = 0\n",
    "        for i in range(len(y_test)):\n",
    "            real_influence_matrix = y_test[i]['influence_matrix']\n",
    "\n",
    "            # Random model prediction:\n",
    "            pred_random_influence_matrix = np.matrix(utils.make_matrix_row_stochastic(\n",
    "                np.random.rand(4, 4)))\n",
    "            random_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_random_influence_matrix)\n",
    "\n",
    "            # Uniform prediction:\n",
    "            pred_uniform_influence_matrix = np.matrix(np.ones((4, 4)) * 0.25)\n",
    "            uniform_err += compute_matrix_err(\n",
    "                real_influence_matrix, pred_uniform_influence_matrix)\n",
    "\n",
    "            # Model's prediction:\n",
    "            predicted_influence_matrix = predicted[i]\n",
    "            predicted_influence_matrix = utils.make_matrix_row_stochastic(\n",
    "                np.matrix(np.reshape(predicted_influence_matrix, (4, 4))))\n",
    "            model_err += compute_matrix_err(\n",
    "                real_influence_matrix, predicted_influence_matrix)\n",
    "\n",
    "        model_err /= len(y_test)\n",
    "        uniform_err /= len(y_test)\n",
    "        random_err /= len(y_test)\n",
    "\n",
    "        model_errs.append(model_err)\n",
    "        random_errs.append(random_err)\n",
    "        uniform_errs.append(uniform_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03664407338947057"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(abs(real_influence_matrix - predicted_influence_matrix)) / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018749999999999996"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(abs(real_influence_matrix - np.ones((4, 4)) * 0.25)) / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0.6446830015922933 +- 0.0\n",
      "uniform: 0.33884002156124987 +- 0.0\n",
      "model: 0.34167516294361333 +- 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3cf43fca58>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model_errs)\n",
    "# plt.hist(random_errs)\n",
    "plt.hist(uniform_errs)\n",
    "# plt.legend(['model', 'random', 'uniform']);\n",
    "plt.legend(['model', 'uniform'])\n",
    "\n",
    "print('random: {} +- {}'.format(np.mean(random_errs), np.std(random_errs)))\n",
    "print('uniform: {} +- {}'.format(np.mean(uniform_errs), np.std(uniform_errs)))\n",
    "print('model: {} +- {}'.format(np.mean(model_errs), np.std(model_errs)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
