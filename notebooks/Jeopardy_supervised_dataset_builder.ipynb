{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# Generating a supervised dataset from the Jeopardy-like logs\n",
    "# ===========================================================\n",
    "\n",
    "## Goals:\n",
    "####   1. Generate different networks from log (sentiment, emotion, and reply duration based)\n",
    "####   2. Generate text embedding data\n",
    "####   3. Map all to influence (appraisal) matrix as the groundtruth to estimate\n",
    "####   4. Use LSTM to take the order (time) also into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last update: 02 Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "import heapq\n",
    "import imp\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "%matplotlib inline\n",
    "\n",
    "# import Softmax_Loss\n",
    "import text_processor\n",
    "import pogs_jeopardy_log_lib\n",
    "import broadcast_network_extraction\n",
    "import utils\n",
    "from mytimer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload():\n",
    "    imp.reload(pogs_jeopardy_log_lib)\n",
    "    imp.reload(text_processor)\n",
    "    imp.reload(utils)\n",
    "    imp.reload(broadcast_network_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_extractor = broadcast_network_extraction.NetworkExtraction()\n",
    "content_fixer = text_processor.FormalEnglishTranslator('../bagofwords/slang.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/omid/Datasets/Jeopardy/'\n",
    "time_window = [2, 10]\n",
    "apply_content_fixer = True\n",
    "fix_spelling = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading teams' logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/pogs_jeopardy_log_lib.py:392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  event_log_no_message[\"sender_subject_id\"] = pd.to_numeric(event_log_no_message[\"sender_subject_id\"])\n",
      "../src/pogs_jeopardy_log_lib.py:642: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  elNoMessage[\"sender_subject_id\"] = pd.to_numeric(elNoMessage[\"sender_subject_id\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 10 ...\n",
      "Processing team 11 ...\n",
      "Processing team 12 ...\n",
      "Processing team 13 ...\n",
      "Processing team 14 ...\n",
      "Processing team 15 ...\n",
      "Processing team 16 ...\n",
      "Processing team 17 ...\n",
      "Processing team 19 ...\n",
      "Processing team 20 ...\n",
      "Processing team 21 ...\n",
      "Processing team 22 ...\n",
      "Processing team 23 ...\n",
      "Processing team 27 ...\n",
      "Processing team 28 ...\n",
      "Processing team 30 ...\n",
      "Processing team 31 ...\n",
      "Processing team 32 ...\n",
      "Processing team 33 ...\n",
      "Processing team 34 ...\n",
      "Processing team 35 ...\n",
      "Processing team 36 ...\n",
      "Processing team 37 ...\n",
      "Processing team 38 ...\n",
      "Processing team 39 ...\n",
      "Processing team 40 ...\n",
      "Processing team 41 ...\n",
      "Processing team 42 ...\n",
      "Processing team 43 ...\n",
      "Processing team 44 ...\n",
      "Processing team 45 ...\n",
      "Processing team 46 ...\n",
      "Processing team 47 ...\n",
      "Processing team 48 ...\n",
      "Processing team 49 ...\n",
      "Processing team 50 ...\n",
      "Team 50 is not found in the logs. There is nothing we can do.\n",
      "Processing team 54 ...\n",
      "Team 54 is not found in the logs. There is nothing we can do.\n",
      "Processing team 61 ...\n",
      "Team 61 is not found in the logs. There is nothing we can do.\n",
      "Processing team 62 ...\n",
      "Team 62 is not found in the logs. There is nothing we can do.\n",
      "Processing team 63 ...\n",
      "Team 63 is not found in the logs. There is nothing we can do.\n",
      "Processing team 69 ...\n",
      "Team 69 is not found in the logs. There is nothing we can do.\n",
      "Processing team 70 ...\n",
      "Processing team 71 ...\n",
      "Processing team 72 ...\n",
      "Processing team 73 ...\n",
      "Processing team 74 ...\n",
      "Processing team 75 ...\n",
      "Processing team 77 ...\n",
      "Processing team 79 ...\n",
      "Processing team 80 ...\n",
      "Team 80 is not found in the logs. There is nothing we can do.\n",
      "Processing team 82 ...\n",
      "Processing team 84 ...\n",
      "Processing team 85 ...\n",
      "Processing team 86 ...\n",
      "Team 86 is not found in the logs. There is nothing we can do.\n",
      "Processing team 87 ...\n",
      "Processing team 88 ...\n",
      "It took 12.35 minutes.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    teams = pd.read_csv(\n",
    "        directory+\"team.csv\",\n",
    "        sep=',',\n",
    "        quotechar=\"|\",\n",
    "        names=[\"id\",\"sessionId\",\"roundId\", \"taskId\"])\n",
    "    data = {}\n",
    "    for team_id in teams.id:\n",
    "        print(\"Processing team\", team_id, '...')\n",
    "        try:\n",
    "            data[team_id] = pogs_jeopardy_log_lib.TeamLogProcessor(\n",
    "                team_id=team_id, logs_directory_path=directory)\n",
    "        except pogs_jeopardy_log_lib.EventLogsNotLoadedError as e:\n",
    "            print('Team {} is not found in the logs. There is nothing we can do.'.format(team_id))\n",
    "            continue\n",
    "        except Exception as e2:\n",
    "            print('Team {} had some problems. Check.'.format(team_id))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/omid/Datasets/Jeopardy/Teams_logs.pk is successfully saved.\n"
     ]
    }
   ],
   "source": [
    "utils.save_it(data, directory+'Teams_logs.pk', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 70, 71, 72, 73, 74, 75, 77, 79, 82, 84, 85, 87, 88])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 :  8 9\n",
      "16 :  3 2\n",
      "27 :  2 1\n",
      "35 :  1 0\n",
      "40 :  7 6\n",
      "70 :  7 8\n"
     ]
    }
   ],
   "source": [
    "# for team_id, team_log in data.items():\n",
    "#     messagesby5 = len(team_log.messages) // 5\n",
    "#     matrices = len(team_log.member_influences)\n",
    "#     if messagesby5 != matrices:\n",
    "#         print(team_id, ': ', messagesby5, matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the language of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 1.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    if apply_content_fixer:\n",
    "        for team_id, team_log in data.items():\n",
    "            for i in range(len(team_log.messages)):\n",
    "                team_log.messages[i] = content_fixer.translate_messages(\n",
    "                    messages=team_log.messages[i],\n",
    "                    message_column_name='event_content',\n",
    "                    fix_spelling=fix_spelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting differnet networks from the combined logs before reporting appraisal networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 35.49 seconds.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-6fd1e0b850f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mtime_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mweight_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbroadcast_network_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeightType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREPLY_DURATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 aggregation_type=broadcast_network_extraction.AggregationType.AVERAGE)\n\u001b[0m\u001b[1;32m     16\u001b[0m             sentiment_net = net_extractor.extract_network_from_broadcast(\n\u001b[1;32m     17\u001b[0m                 \u001b[0mcommunication_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_messages_before_appraisal_report\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/Dropbox/PhD/Projects/Appraisal Network Estimation/appraisal_network_dynamics/src/broadcast_network_extraction.py\u001b[0m in \u001b[0;36mextract_network_from_broadcast\u001b[0;34m(self, communication_data, time_window, weight_type, aggregation_type, column_names, gamma)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 text_column_name, time_column_name, sender_column_name])\n\u001b[1;32m    256\u001b[0m         \u001b[0mdgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunication_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_column_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             communication_data[time_column_name] = (\n\u001b[1;32m    259\u001b[0m                 pd.to_datetime(communication_data[time_column_name]))\n",
      "\u001b[0;32m/home/omid/.local/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/.local/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/omid/.local/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "with Timer():\n",
    "    networks = {}\n",
    "    for team_id, team_log in data.items():\n",
    "        this_team_nets = []\n",
    "        this_team_number_of_networks = min(\n",
    "            len(team_log.messages) // 5,\n",
    "            len(team_log.member_influences))\n",
    "        for i in range(len(team_log.messages) // 5):\n",
    "            all_messages_before_appraisal_report = pd.concat(\n",
    "                [team_log.messages[i] for i in np.arange(i * 5, i * 5 + 5)])\n",
    "            reply_duration_net = net_extractor.extract_network_from_broadcast(            \n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.REPLY_DURATION,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.AVERAGE)\n",
    "            sentiment_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.REPLY_DURATION,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.AVERAGE)\n",
    "            emotion_arousal_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.EMOTION_AROUSAL,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.AVERAGE)\n",
    "            emotion_dominance_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.EMOTION_DOMINANCE,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.AVERAGE)\n",
    "            emotion_valence_net = net_extractor.extract_network_from_broadcast(\n",
    "                communication_data=all_messages_before_appraisal_report,\n",
    "                time_window=time_window,\n",
    "                weight_type=broadcast_network_extraction.WeightType.EMOTION_VALENCE,\n",
    "                aggregation_type=broadcast_network_extraction.AggregationType.AVERAGE)\n",
    "            this_team_nets.append({\n",
    "                'sentiment': sentiment_net,\n",
    "                'reply_duration': reply_duration_net,\n",
    "                'emotion_arousal': emotion_arousal_net,\n",
    "                'emotion_dominance': emotion_dominance_net,\n",
    "                'emotion_valence': emotion_valence_net})\n",
    "        if len(this_team_nets) > 1:\n",
    "            networks[team_id] = this_team_nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_it(networks, directory+'Teams_networks.pk', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
